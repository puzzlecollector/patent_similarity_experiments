{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a979570-6fb7-4b0b-ba3f-5b9494670503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler, IterableDataset\n",
    "from pytorch_metric_learning import miners, losses\n",
    "from pytorch_metric_learning.distances import CosineSimilarity\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.strategies.ddp import DDPStrategy\n",
    "from pytorch_lightning.callbacks import BasePredictionWriter\n",
    "from pytorch_lightning.core.saving import load_hparams_from_yaml, update_hparams\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "import addict\n",
    "import argparse\n",
    "\n",
    "# for calculating MRR \n",
    "from scipy.spatial import distance \n",
    "from functools import partial \n",
    "from tqdm.contrib.concurrent import process_map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4222fd73-578d-48e1-951f-6b34401ca95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletData(Dataset): \n",
    "    def __init__(self, path): \n",
    "        super().__init__() \n",
    "        self.data = [] \n",
    "        with Path(path).open(\"r\", encoding=\"utf8\") as f:\n",
    "            for i, triplet in enumerate(f):\n",
    "                if i == 0:\n",
    "                    continue \n",
    "                try: \n",
    "                    query, positive, negative = triplet.strip().split(\",\") \n",
    "                    data = [] \n",
    "                    data.append(\"../storage/kr_triplet_v1.1/{}.txt\".format(query)) \n",
    "                    data.append(\"../storage/kr_triplet_v1.1/{}.txt\".format(positive)) \n",
    "                    data.append(\"../storage/kr_triplet_v1.1/{}.txt\".format(negative)) \n",
    "                    self.data.append(data) \n",
    "                except: \n",
    "                    continue \n",
    "    def __getitem__(self, index): \n",
    "        return self.data[index] \n",
    "    def __len__(self): \n",
    "        return len(self.data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "041d836d-8f69-455d-92af-e3a8272d6ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_collate(object): \n",
    "    def __init__(self, plm=\"tanapatentlm/patent-ko-deberta\"): \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(plm) \n",
    "        self.tokenizer.add_special_tokens({\"additional_special_tokens\": [\"[IPC]\", \"[TTL]\", \"[CLMS]\", \"[ABST]\"]}) \n",
    "        self.chunk_size = 1024 \n",
    "    def __call__(self, batch): \n",
    "        input_ids, attn_masks, labels = [], [], [] \n",
    "        ids = 0 \n",
    "        for idx, triplet in enumerate(batch): \n",
    "            try: \n",
    "                query_txt, positive_txt, negative_txt = triplet\n",
    "                with Path(query_txt).open(\"r\", encoding=\"utf8\") as f: \n",
    "                    q = f.read() \n",
    "                with Path(positive_txt).open(\"r\", encoding=\"utf8\") as f: \n",
    "                    p = f.read() \n",
    "                with Path(negative_txt).open(\"r\", encoding=\"utf8\") as f: \n",
    "                    n = f.read() \n",
    "                encoded_q = self.tokenizer(q, return_tensors=\"pt\", max_length=self.chunk_size, padding=\"max_length\", truncation=True) \n",
    "                encoded_p = self.tokenizer(p, return_tensors=\"pt\", max_length=self.chunk_size, padding=\"max_length\", truncation=True)  \n",
    "                encoded_n = self.tokenizer(n, return_tensors=\"pt\", max_length=self.chunk_size, padding=\"max_length\", truncation=True) \n",
    "                \n",
    "                input_ids.append(encoded_q[\"input_ids\"]) \n",
    "                attn_masks.append(encoded_q[\"attention_mask\"]) \n",
    "                labels.append(ids*2) \n",
    "                \n",
    "                input_ids.append(encoded_p[\"input_ids\"]) \n",
    "                attn_masks.append(encoded_p[\"attention_mask\"]) \n",
    "                labels.append(ids*2) \n",
    "\n",
    "                input_ids.append(encoded_n[\"input_ids\"]) \n",
    "                attn_masks.append(encoded_n[\"attention_mask\"]) \n",
    "                labels.append(ids*2+1) \n",
    "                ids += 1 \n",
    "\n",
    "            except Exception as e:\n",
    "                print(e) \n",
    "                print(\"===\"*100) \n",
    "                continue \n",
    "        input_ids = torch.stack(input_ids, dim=0).squeeze(dim=1) \n",
    "        attn_masks = torch.stack(attn_masks, dim=0).squeeze(dim=1) \n",
    "        labels = torch.tensor(labels, dtype=int) \n",
    "        return input_ids, attn_masks, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f97915a5-8e82-4c78-90e4-ea4bf9f8dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralRanker(pl.LightningModule): \n",
    "    def __init__(self, hparams=dict(), plm=\"tanapatentlm/patent-ko-deberta\"): \n",
    "        super(NeuralRanker, self).__init__() \n",
    "        self.hparams.update(hparams) \n",
    "        self.save_hyperparameters(ignore=\"hparams\") \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(plm) \n",
    "        self.config = AutoConfig.from_pretrained(plm) \n",
    "        self.metric = losses.MultiSimilarityLoss() \n",
    "        self.miner = miners.MultiSimilarityMiner() \n",
    "        self.net = AutoModel.from_pretrained(plm) \n",
    "        if \"additional_special_tokens\" in self.hparams and self.hparams[\"additional_special_tokens\"]: \n",
    "            additional_special_tokens = self.hparams[\"additional_special_tokens\"] \n",
    "            self.tokenizer.add_special_tokens({\"additional_special_tokens\": additional_special_tokens}) \n",
    "            self.net.resize_token_embeddings(len(self.tokenizer)) \n",
    "\n",
    "    def mean_pooling(self, model_output, attention_mask): \n",
    "        token_embeddings = model_output[0] \n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float() \n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9) \n",
    "\n",
    "    def forward(self, input_ids, attention_mask): \n",
    "        model_output = self.net(input_ids, attention_mask) \n",
    "        model_output = self.mean_pooling(model_output, attention_mask) \n",
    "        return model_output \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), \n",
    "                                      lr=float(self.hparams.lr), \n",
    "                                      weight_decay=float(self.hparams.weight_decay), \n",
    "                                      eps=float(self.hparams.adam_epsilon)) \n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, \n",
    "            num_warmup_steps=self.hparams.warmup_steps, \n",
    "            num_training_steps=self.trainer.estimated_stepping_batches,\n",
    "        ) \n",
    "        scheduler = {\"scheduler\":scheduler, \"interval\":\"step\", \"frequency\":1} \n",
    "        return [optimizer], [scheduler] \n",
    "\n",
    "    def training_step(self, batch, batch_idx): \n",
    "        input_ids, attn_masks, labels = batch \n",
    "        embeddings = self(input_ids, attn_masks) \n",
    "        hard_pairs = self.miner(embeddings, labels) \n",
    "        loss = self.metric(embeddings, labels, hard_pairs) \n",
    "        self.log(\"train_loss\", loss, batch_size=len(batch)) \n",
    "        return {\"loss\":loss} \n",
    "\n",
    "    def validation_step(self, batch, batch_idx): \n",
    "        input_ids, attn_masks, labels = batch \n",
    "        embeddings = self(input_ids, attn_masks) \n",
    "        loss = self.metric(embeddings, labels) \n",
    "        self.log(\"val_loss\", loss, batch_size=len(batch)) \n",
    "        return {\"val_loss\":loss} \n",
    "\n",
    "    def validation_epoch_end(self, outputs): \n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean() \n",
    "        print(f\"\\nEpoch {self.current_epoch} | avg_loss: {avg_loss}\\n\") \n",
    "\n",
    "    def predict_step(self, batch, batch_idx: int, dataloader_idx: int=0): \n",
    "        q_input_ids, q_attn_masks = batch[\"q\"][\"input_ids\"], batch[\"q\"][\"attention_mask\"] \n",
    "        q_emb = self(q_input_ids, q_attn_masks) \n",
    "        return q_emb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f91a7cb-e079-4304-ba3f-8a27705c77fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1020130067084</td>\n",
       "      <td>1020130008422</td>\n",
       "      <td>1013294870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1020130065171</td>\n",
       "      <td>1020120081496</td>\n",
       "      <td>1020200140972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1020130065171</td>\n",
       "      <td>1011789270000</td>\n",
       "      <td>1020140091466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1020130065755</td>\n",
       "      <td>1020130033621</td>\n",
       "      <td>1020150115926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020130062194</td>\n",
       "      <td>1020130028620</td>\n",
       "      <td>1021316260000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         queries      positives      negatives\n",
       "0  1020130067084  1020130008422  1013294870000\n",
       "1  1020130065171  1020120081496  1020200140972\n",
       "2  1020130065171  1011789270000  1020140091466\n",
       "3  1020130065755  1020130033621  1020150115926\n",
       "4  1020130062194  1020130028620  1021316260000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_triplets = pd.read_csv(\"kr_triplet_test.csv\") \n",
    "\n",
    "test_triplets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ade2f7dc-ce61-4021-b297-4584e34c8f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tanapatentlm/patent-ko-deberta were not used when initializing DebertaV2Model: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "test_set = TripletData(\"kr_triplet_test.csv\") \n",
    "collate = custom_collate() \n",
    "test_dataloader = DataLoader(test_set, batch_size=1, collate_fn=collate, shuffle=False) \n",
    "parser = argparse.ArgumentParser() \n",
    "parser.add_argument(\"--setting\", \"-s\", type=str, default=\"default.yaml\", help=\"experiment setting\") \n",
    "args = parser.parse_args(args=[]) \n",
    "hparams = addict.Addict(dict(load_hparams_from_yaml(args.setting)))\n",
    "\n",
    "model = NeuralRanker(hparams)\n",
    "model_pt_path = Path(\"KR_Ranker_epoch_end_checkpoints-epoch=02-val_loss=0.26689678.ckpt\") \n",
    "device = torch.device(\"cuda\") \n",
    "checkpoint = torch.load(model_pt_path, map_location=device)\n",
    "loaded_dict = checkpoint[\"state_dict\"] \n",
    "print(model.load_state_dict(loaded_dict))\n",
    "model.eval()\n",
    "model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5194c6af-9406-4b33-b8a3-82acf913c25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.cuda() \n",
    "print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cafedfef-8687-4b58-85d2-727d3cdda5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25d99041f7e4f2fb3596728b2b604ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") \n",
    "\n",
    "queries, positives, negatives = [], [], [] \n",
    "\n",
    "for step, batch in enumerate(tqdm(test_dataloader, position=0, leave=True)): \n",
    "    input_ids, attn_masks, labels = batch \n",
    "    input_ids = input_ids.to(device) \n",
    "    attn_masks = attn_masks.to(device) \n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        output = model(input_ids, attn_masks) \n",
    "    \n",
    "    queries.append(output[0]) \n",
    "    positives.append(output[1]) \n",
    "    negatives.append(output[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27703caf-4375-4ef8-863b-915472303519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4213, 4213, 4213)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries), len(positives), len(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83421e46-99e0-4e5d-a291-89aa2262c9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424508fd16ba4b17b0c088eb7a94d076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f381693ba17d42c99078782c947adb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2113e58ea8b3487bb9604fac8aacb0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4213, 2048) (4213, 2048) (4213, 2048)\n",
      "(8426, 2048)\n",
      "saving embeddings...\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "q_v, p_v, n_v = [], [], [] \n",
    "\n",
    "for q in tqdm(queries): \n",
    "    q_v.append(q.detach().cpu().numpy().copy().reshape((-1,2048))) \n",
    "\n",
    "for p in tqdm(positives): \n",
    "    p_v.append(p.detach().cpu().numpy().copy().reshape((-1,2048))) \n",
    "\n",
    "for n in tqdm(negatives): \n",
    "    n_v.append(n.detach().cpu().numpy().copy().reshape((-1,2048))) \n",
    "    \n",
    "q_v = np.concatenate(q_v, axis=0) \n",
    "p_v = np.concatenate(p_v, axis=0) \n",
    "n_v = np.concatenate(n_v, axis=0) \n",
    "\n",
    "print(q_v.shape, p_v.shape, n_v.shape) \n",
    "\n",
    "candidate = np.concatenate([p_v, n_v], axis=0) \n",
    "\n",
    "print(candidate.shape) \n",
    "\n",
    "embeddings = {\n",
    "    \"query\": q_v, \n",
    "    \"candidate\": candidate \n",
    "} \n",
    "\n",
    "print(\"saving embeddings...\") \n",
    "with open(\"kr_embeddings.pkl\", \"wb\") as f: \n",
    "    pickle.dump(embeddings, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57095b7b-6c0a-4d17-a179-dfce5ee2723e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf473f0784ec48df9b162ea4b2537bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\" \n",
    "\n",
    "def get_rank(inp, candidate): \n",
    "    i, q = inp \n",
    "    distances = distance.cdist([q], candidate.copy(), \"cosine\")[0] \n",
    "    rank = np.argsort(distances) \n",
    "    return rank[0], np.where(rank==i)[0][0] + 1 \n",
    "\n",
    "ranks = process_map(partial(get_rank, candidate=candidate), \n",
    "                    enumerate(q_v), \n",
    "                    total=len(q_v), \n",
    "                    max_workers=32) \n",
    "\n",
    "p1, rank = zip(*ranks) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8874242b-f475-4abc-8746-6231b5faf1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1000: 0.0010815775511349701\n"
     ]
    }
   ],
   "source": [
    "rrank = [] \n",
    "\n",
    "for r in rank: \n",
    "    if r <= 1000: \n",
    "        rrank.append(1/r) \n",
    "    else:\n",
    "        rrank.append(0) \n",
    "\n",
    "print(f\"MRR@1000: {np.mean(rrank)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77f81b4e-4bb1-4f3c-98a4-7c3c55bb839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average rank: 4031.218609067173\n"
     ]
    }
   ],
   "source": [
    "print(f\"average rank: {np.mean(rank)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4b0d0d-336e-4a4e-b870-71443fe825cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b04ae-c56d-47e8-b771-429344d2c344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0bc2b-1735-41e6-9ba1-a95b6b01b2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dd21b3-edea-43dc-a7dd-7ae2fc2582e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2ca489-49d7-46cd-8426-6ad94d817f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
