{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "471d6dfd-5897-4560-9454-ceafca3aa6c4",
   "metadata": {},
   "source": [
    "# CE Sentence Ranker 설명 \n",
    "- 유니크한 IPC 기준 8:1:1로 골드 데이터셋 스플릿 후 cross encoder 학습 \n",
    "- cross encoder는 DeBERTa-Large 기반, Doc Ranker에서 전이학습을 했고 loss는 RMSE를 사용 \n",
    "- 10 에포크 학습. Validation loss는 0.1-0.2 RMSE 정도\n",
    "- 한개의 쿼리 문장당 100개 이상의 후보 문장들 존재 \n",
    "- A100-80GB 한장 기준, 배치 사이즈 없이 하나씩 처리할때 cross encoder로 계산하는데 3초가 걸린다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60d2103a-cece-4d2a-9922-0dd620e2d631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "from tqdm.auto import tqdm \n",
    "from transformers import (\n",
    "    AdamW, \n",
    "    AutoConfig, \n",
    "    AutoModel, \n",
    "    AutoTokenizer, \n",
    "    get_linear_schedule_with_warmup\n",
    ") \n",
    "import torch \n",
    "import torch.nn.functional as F \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, RandomSampler, SequentialSampler, IterableDataset\n",
    "import math \n",
    "import time \n",
    "import datetime \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3227519-cbcb-4342-b4ea-719032e2296d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2590216"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(\"../storage/FGH_spec_ind_claim_triplet_v1.4.1s\") \n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "595f5384-dc65-4e10-b580-60d8c69895d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"0919_라벨링세트_9주차_병합.xlsx\")\n",
    "\n",
    "df = df.loc[df[\"라벨링\"].notnull(), [\"쿼리 번호\", \"IPC 분류\", \"쿼리 문장\", \"후보 문장\", \"쿼리 문서 번호\", \"Positive 문서 번호\", \"라벨링\"]] \n",
    "df = df.dropna() \n",
    "labels_fixed = [] \n",
    "labels = df[\"라벨링\"].values \n",
    "\n",
    "for i in range(len(labels)): \n",
    "    if labels[i] == 0.1:\n",
    "        labels_fixed.append(1.0) \n",
    "    elif labels[i] not in [0,0.5,0.8,1.0]: \n",
    "        labels_fixed.append(None) \n",
    "    else: \n",
    "        labels_fixed.append(labels[i]) \n",
    "        \n",
    "df[\"라벨링\"] = labels_fixed\n",
    "df = df.dropna() \n",
    "ipc_types = df[\"IPC 분류\"].values \n",
    "unique_ipcs = np.unique(ipc_types) \n",
    "\n",
    "train_size = int(len(unique_ipcs) * 0.8) \n",
    "val_size = int(len(unique_ipcs) * 0.1) \n",
    "\n",
    "train_unique_ipcs = unique_ipcs[:train_size] \n",
    "val_unique_ipcs = unique_ipcs[train_size:train_size+val_size] \n",
    "test_unique_ipcs = unique_ipcs[train_size+val_size:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dd41058-ae64-4e45-803e-595ae0ae17b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>쿼리 번호</th>\n",
       "      <th>IPC 분류</th>\n",
       "      <th>쿼리 문장</th>\n",
       "      <th>후보 문장</th>\n",
       "      <th>쿼리 문서 번호</th>\n",
       "      <th>Positive 문서 번호</th>\n",
       "      <th>라벨링</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>F21V504</td>\n",
       "      <td>an adjustable lens positioned so as to alter ...</td>\n",
       "      <td>Several mechanisms for altering the beam prod...</td>\n",
       "      <td>20080259600</td>\n",
       "      <td>6474837</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>F21V504</td>\n",
       "      <td>an adjustable lens positioned so as to alter ...</td>\n",
       "      <td>When a plurality of aperture plates are incor...</td>\n",
       "      <td>20080259600</td>\n",
       "      <td>6474837</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166</td>\n",
       "      <td>F21V504</td>\n",
       "      <td>an adjustable lens positioned so as to alter ...</td>\n",
       "      <td>By deforming the base member 20 in Bailey, th...</td>\n",
       "      <td>20080259600</td>\n",
       "      <td>6474837</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>166</td>\n",
       "      <td>F21V504</td>\n",
       "      <td>an adjustable lens positioned so as to alter ...</td>\n",
       "      <td>Beam modifying optics are used to alter the f...</td>\n",
       "      <td>20080259600</td>\n",
       "      <td>6474837</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>F21V504</td>\n",
       "      <td>an adjustable lens positioned so as to alter ...</td>\n",
       "      <td>For an aperture plate with light refractive o...</td>\n",
       "      <td>20080259600</td>\n",
       "      <td>6474837</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33695</th>\n",
       "      <td>4207</td>\n",
       "      <td>G06F017/60</td>\n",
       "      <td>using a death benefit value of the policy for ...</td>\n",
       "      <td>As the investment in the life insurance policy...</td>\n",
       "      <td>20100000000</td>\n",
       "      <td>20000000000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33696</th>\n",
       "      <td>4207</td>\n",
       "      <td>G06F017/60</td>\n",
       "      <td>using a death benefit value of the policy for ...</td>\n",
       "      <td>This database provides historical or anticipat...</td>\n",
       "      <td>20100000000</td>\n",
       "      <td>20000000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33697</th>\n",
       "      <td>4207</td>\n",
       "      <td>G06F017/60</td>\n",
       "      <td>using a death benefit value of the policy for ...</td>\n",
       "      <td>3 shows the process for determining the monthl...</td>\n",
       "      <td>20100000000</td>\n",
       "      <td>20000000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33698</th>\n",
       "      <td>4207</td>\n",
       "      <td>G06F017/60</td>\n",
       "      <td>using a death benefit value of the policy for ...</td>\n",
       "      <td>For example the lender may require additional ...</td>\n",
       "      <td>20100000000</td>\n",
       "      <td>20000000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33699</th>\n",
       "      <td>4207</td>\n",
       "      <td>G06F017/60</td>\n",
       "      <td>using a death benefit value of the policy for ...</td>\n",
       "      <td>The proceeds of the investment vehicle are per...</td>\n",
       "      <td>20100000000</td>\n",
       "      <td>20000000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33077 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       쿼리 번호      IPC 분류                                              쿼리 문장  \\\n",
       "0        166     F21V504   an adjustable lens positioned so as to alter ...   \n",
       "1        166     F21V504   an adjustable lens positioned so as to alter ...   \n",
       "2        166     F21V504   an adjustable lens positioned so as to alter ...   \n",
       "3        166     F21V504   an adjustable lens positioned so as to alter ...   \n",
       "4        166     F21V504   an adjustable lens positioned so as to alter ...   \n",
       "...      ...         ...                                                ...   \n",
       "33695   4207  G06F017/60  using a death benefit value of the policy for ...   \n",
       "33696   4207  G06F017/60  using a death benefit value of the policy for ...   \n",
       "33697   4207  G06F017/60  using a death benefit value of the policy for ...   \n",
       "33698   4207  G06F017/60  using a death benefit value of the policy for ...   \n",
       "33699   4207  G06F017/60  using a death benefit value of the policy for ...   \n",
       "\n",
       "                                                   후보 문장     쿼리 문서 번호  \\\n",
       "0       Several mechanisms for altering the beam prod...  20080259600   \n",
       "1       When a plurality of aperture plates are incor...  20080259600   \n",
       "2       By deforming the base member 20 in Bailey, th...  20080259600   \n",
       "3       Beam modifying optics are used to alter the f...  20080259600   \n",
       "4       For an aperture plate with light refractive o...  20080259600   \n",
       "...                                                  ...          ...   \n",
       "33695  As the investment in the life insurance policy...  20100000000   \n",
       "33696  This database provides historical or anticipat...  20100000000   \n",
       "33697  3 shows the process for determining the monthl...  20100000000   \n",
       "33698  For example the lender may require additional ...  20100000000   \n",
       "33699  The proceeds of the investment vehicle are per...  20100000000   \n",
       "\n",
       "      Positive 문서 번호  라벨링  \n",
       "0            6474837  0.8  \n",
       "1            6474837  0.0  \n",
       "2            6474837  0.5  \n",
       "3            6474837  0.8  \n",
       "4            6474837  1.0  \n",
       "...              ...  ...  \n",
       "33695    20000000000  0.5  \n",
       "33696    20000000000  0.0  \n",
       "33697    20000000000  0.0  \n",
       "33698    20000000000  0.0  \n",
       "33699    20000000000  0.0  \n",
       "\n",
       "[33077 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69e65489-9e8d-40aa-a465-2059d2df7c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339349521ceb42a7b980cd5a41aa6e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make sure to only test with samples with at least one 0.8 or 1.0 score. \n",
    "train_queries, train_candidates, train_labels = [], [], [] \n",
    "valid_queries, valid_candidates, valid_labels = [], [], [] \n",
    "test_queries, test_candidates, test_labels = [], [], [] \n",
    "test_query_nums, test_candidate_nums = [], [] \n",
    "\n",
    "ipcs = df[\"IPC 분류\"].values \n",
    "queries = df[\"쿼리 문장\"].values \n",
    "candidates = df[\"후보 문장\"].values \n",
    "labels = df[\"라벨링\"].values\n",
    "query_nums = df[\"쿼리 문서 번호\"].values \n",
    "positive_nums = df[\"Positive 문서 번호\"].values \n",
    "\n",
    "for i in tqdm(range(len(queries)), position=0, leave=True): \n",
    "    if ipcs[i] in train_unique_ipcs: \n",
    "        train_queries.append(queries[i]) \n",
    "        train_candidates.append(candidates[i]) \n",
    "        train_labels.append(labels[i]) \n",
    "    elif ipcs[i] in val_unique_ipcs: \n",
    "        valid_queries.append(queries[i]) \n",
    "        valid_candidates.append(candidates[i]) \n",
    "        valid_labels.append(labels[i]) \n",
    "    elif ipcs[i] in test_unique_ipcs: \n",
    "        test_queries.append(queries[i]) \n",
    "        test_candidates.append(candidates[i]) \n",
    "        test_labels.append(labels[i])  \n",
    "        test_query_nums.append(query_nums[i]) \n",
    "        test_candidate_nums.append(positive_nums[i])  \n",
    "        \n",
    "        \n",
    "# for inference, we only use test data. Train and valid wree used for training our cross encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ef3b893c-85ad-46f1-af3d-c51d7139685f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['쿼리 번호', 'IPC 분류', '쿼리 문장', '후보 문장', '쿼리 문서 번호', 'Positive 문서 번호',\n",
       "       '라벨링'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fb3362d0-0367-4a1a-8f08-c93c1124da59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tanapatentlm/patentdeberta_large_spec_128_pwi were not used when initializing DebertaModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc131261e1a413e99170d9e731ef1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../storage/FGH_spec_ind_claim_triplet_v1.4.1s/20090163784.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [124]\u001b[0m, in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m splitted_sentences \u001b[38;5;241m=\u001b[39m [] \n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc_num \u001b[38;5;129;01min\u001b[39;00m candidate_doc_num: \n\u001b[0;32m---> 79\u001b[0m     split_batch \u001b[38;5;241m=\u001b[39m \u001b[43msplit_sentences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_num\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     80\u001b[0m     splitted_sentences\u001b[38;5;241m.\u001b[39mextend(split_batch) \n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# splitted_sentences = split_sentences(candidate_doc_num) \u001b[39;00m\n",
      "Input \u001b[0;32mIn [124]\u001b[0m, in \u001b[0;36msplit_sentences\u001b[0;34m(doc_num, L)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_sentences\u001b[39m(doc_num, L\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m): \u001b[38;5;66;03m# L is the threshold for sentence length \u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../storage/FGH_spec_ind_claim_triplet_v1.4.1s/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdoc_num\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f: \n\u001b[1;32m     43\u001b[0m         doc \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread() \n\u001b[1;32m     44\u001b[0m     positive_doc \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../storage/FGH_spec_ind_claim_triplet_v1.4.1s/20090163784.txt'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "First, we will get all the unique test_queries \n",
    "Second, for each test query we get all the corresponding candidate sentences, candidate labels and we also get the candidate document number \n",
    "Get all sentences from the candidate document and then merge with the obtained candidate sentences. Give zero labels for all candidate sentences that are not in the labeled dataframe. \n",
    "Store array of tuples (query, candidate, actual score, predicted score) and sort in descending order based on predicted score \n",
    "'''\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tanapatentlm/patentdeberta_large_spec_128_pwi\")\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# define model \n",
    "class SentenceRanker(nn.Module): \n",
    "    def __init__(self, plm=\"tanapatentlm/patentdeberta_large_spec_128_pwi\"): \n",
    "        super(SentenceRanker, self).__init__() \n",
    "        self.config = AutoConfig.from_pretrained(plm)  \n",
    "        self.net = AutoModel.from_pretrained(plm) \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(plm) \n",
    "        self.tokenizer.add_special_tokens({\"additional_special_tokens\":[\"[IPC]\", \"[TTL]\", \"[CLMS]\", \"[ABST]\"]}) \n",
    "        self.net.resize_token_embeddings(len(self.tokenizer))\n",
    "        self.dropout = nn.Dropout(0.1) \n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1) \n",
    "        \n",
    "    def mean_pooling(self, model_output, attention_mask): \n",
    "        token_embeddings = model_output[0] \n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float() \n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask): \n",
    "        x = self.net(input_ids, attention_mask) \n",
    "        x = self.mean_pooling(x, attention_mask) \n",
    "        x = self.dropout(x) \n",
    "        x = self.fc(x) \n",
    "        return x \n",
    "\n",
    "print(\"Loading Model...\") \n",
    "model = SentenceRanker() \n",
    "checkpoint = torch.load(\"DeBERTa_Cross_Encoder.pt\") \n",
    "model.load_state_dict(checkpoint) \n",
    "model.cuda() \n",
    "model.eval() \n",
    "\n",
    "def split_sentences(doc_num, L=100): # L is the threshold for sentence length \n",
    "    with open(\"../storage/FGH_spec_ind_claim_triplet_v1.4.1s/\" + str(doc_num) + \".txt\", \"r\") as f: \n",
    "        doc = f.read() \n",
    "    positive_doc = doc.replace(\".\",\";\") \n",
    "    p_ttl = re.search(\"<TTL>([\\s\\S]*?)<IPC>\", positive_doc).group(1)\n",
    "    p_ipc = re.search(\"<IPC>([\\s\\S]*?)<ABST>\", positive_doc).group(1)\n",
    "    p_abst = re.search(\"<ABST>([\\s\\S]*?)<CLMS>\", positive_doc).group(1)\n",
    "    p_clms = re.search(\"<CLMS>([\\s\\S]*?)<DESC>\", positive_doc).group(1)\n",
    "    p_desc = re.search(\"<DESC>([\\s\\S]*)$\", positive_doc).group(1)\n",
    "    splitted_positives = [] \n",
    "    for split in re.split(r\"wherein|[;\\n]+\", p_abst.replace(\".\",\";\")):\n",
    "        if len(split) > L:\n",
    "            splitted_positives.append(split) \n",
    "    for split in re.split(r\"wherein|[;\\n]+\", p_clms.replace(\".\",\";\")):\n",
    "        if len(split) > L:\n",
    "            splitted_positives.append(split) \n",
    "    for split in re.split(r\"wherein|[;\\n]+\", p_desc.replace(\".\",\";\")):\n",
    "        if len(split) > L:\n",
    "            splitted_positives.append(split) \n",
    "    splitted_positives = list(set(splitted_positives))\n",
    "    return splitted_positives \n",
    "\n",
    "\n",
    "test_queries = np.array(test_queries) \n",
    "_, idx = np.unique(test_queries, return_index=True) \n",
    "unique_test_queries = test_queries[np.sort(idx)] \n",
    "\n",
    "saved_tuples = [] # for later analysis \n",
    "ranks = [] \n",
    "\n",
    "for test_query in tqdm(unique_test_queries, desc=\"Inference\", position=0, leave=True):\n",
    "    search_df = df[df[\"쿼리 문장\"]==test_query] \n",
    "    candidates = search_df[\"후보 문장\"].values \n",
    "    candidate_labels = search_df[\"라벨링\"].values \n",
    "    candidate_doc_num = np.unique(search_df[\"Positive 문서 번호\"]) \n",
    "    \n",
    "    splitted_sentences = [] \n",
    "    for doc_num in candidate_doc_num: \n",
    "        split_batch = split_sentences(doc_num) \n",
    "        splitted_sentences.extend(split_batch) \n",
    "        \n",
    "    # splitted_sentences = split_sentences(candidate_doc_num) \n",
    "    all_candidates = np.array(candidates.tolist() + splitted_sentences)\n",
    "    _, idx = np.unique(all_candidates, return_index=True)\n",
    "    all_candidates = all_candidates[np.sort(idx)]\n",
    "    \n",
    "    # give zero label for all sentences that are not in the gold dataset, regardless of whether they are really similar to the query or not. \n",
    "    all_labels = candidate_labels.tolist() + [0 for _ in range(len(all_candidates) - len(candidates))] \n",
    "    \n",
    "    # inference \n",
    "    all_tuples = [] # query, candidate, gold dataset score, predicted score \n",
    "    ce_scores = [] \n",
    "\n",
    "    for i in range(len(all_candidates)):\n",
    "        encoded_input = tokenizer(test_query, all_candidates[i], max_length=256, truncation=True, padding=\"max_length\", return_tensors=\"pt\").to(device) \n",
    "        input_ids = encoded_input[\"input_ids\"] \n",
    "        attn_mask = encoded_input[\"attention_mask\"] \n",
    "        with torch.no_grad(): \n",
    "            output = model(input_ids, attn_mask) \n",
    "        ce_scores.append(output.item()) \n",
    "    \n",
    "    for i in range(len(all_candidates)): \n",
    "        all_tuples.append((test_query, \n",
    "                           all_candidates[i],\n",
    "                           all_labels[i], \n",
    "                           ce_scores[i]))\n",
    "    \n",
    "    \n",
    "    sorted_list = sorted(\n",
    "        all_tuples,\n",
    "        key=lambda t: t[3],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    rank = 0 \n",
    "    for i in range(len(sorted_list)): \n",
    "        if sorted_list[i][2] >= 0.8: \n",
    "            rank = i+1\n",
    "            break \n",
    "            \n",
    "    ranks.append(rank)     \n",
    "    saved_tuples.append(all_tuples) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7df1ac64-5a62-4bc8-962e-5ed54d6347c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24421389252911227"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for r in ranks: \n",
    "    if r <= 1000 and r > 0: \n",
    "        rr.append(1/r) \n",
    "    else:\n",
    "        rr.append(0) \n",
    "        \n",
    "np.mean(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8fbde520-6fd5-4eba-bd83-fb9df32f4db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.470588235294116"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s,cnt = 0,0  \n",
    "for r in ranks: \n",
    "    if r > 0: \n",
    "        s += r \n",
    "        cnt += 1\n",
    "        \n",
    "s / cnt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dead5b-cfa1-4a4c-97ec-6e9dd3a0f50c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf3154d-b5d7-4f86-b7d0-cc3e83de05c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d03572-3653-4d12-9deb-05e78c5d3c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4175b6af-cb0f-4b81-b1e6-1728a3fe20f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
