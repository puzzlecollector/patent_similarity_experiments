{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da358df-2efd-4cd1-946a-8a9b3797e2be",
   "metadata": {},
   "source": [
    "# Testing our Bi-Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d8197b-2cc3-4386-b333-9a49cb8f569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses, util, evaluation \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "from tqdm.auto import tqdm \n",
    "from transformers import (\n",
    "    AdamW, \n",
    "    AutoConfig, \n",
    "    AutoModel, \n",
    "    AutoTokenizer, \n",
    "    get_linear_schedule_with_warmup\n",
    ") \n",
    "import torch \n",
    "import torch.nn.functional as F \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler, IterableDataset\n",
    "import math \n",
    "import time \n",
    "import datetime \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ddbe08d-7472-4e2f-b4c7-917a9c10ebc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2590216"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(\"../storage/FGH_spec_ind_claim_triplet_v1.4.1s\") \n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5bd729d-c9a8-4e0e-9ec9-d3b7814f1e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"0919_라벨링세트_9주차_병합.xlsx\") \n",
    "\n",
    "df = df.loc[df[\"라벨링\"].notnull(), [\"쿼리 번호\", \"IPC 분류\", \"쿼리 문장\", \"후보 문장\", \"쿼리 문서 번호\", \"Positive 문서 번호\", \"라벨링\"]] \n",
    "df = df.dropna() \n",
    "labels_fixed = [] \n",
    "labels = df[\"라벨링\"].values \n",
    "\n",
    "for i in range(len(labels)): \n",
    "    if labels[i] == 0.1: \n",
    "        labels_fixed.append(1.0) \n",
    "    elif labels[i] not in [0, 0.5, 0.8, 1.0]: \n",
    "        labels_fixed.append(None) \n",
    "    else: \n",
    "        labels_fixed.append(labels[i]) \n",
    "\n",
    "df[\"라벨링\"] = labels_fixed \n",
    "df = df.dropna() \n",
    "query_numbers = df[\"쿼리 번호\"].values \n",
    "unique_queries = np.unique(query_numbers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80d258a5-c78c-4f41-959d-2fb3278d7032",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(unique_queries) * 0.8) \n",
    "val_size = int(len(unique_queries) * 0.1) \n",
    "\n",
    "train_unique_queries = unique_queries[:train_size] \n",
    "val_unique_queries = unique_queries[train_size:train_size+val_size] \n",
    "test_unique_queries = unique_queries[train_size+val_size:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db92af3-3c3c-4775-9eaa-09b00da02e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a6740152ca4698ae273ca7e999c94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_queries, train_candidates, train_labels = [], [], [] \n",
    "valid_queries, valid_candidates, valid_labels = [], [], [] \n",
    "test_queries, test_candidates, test_labels = [], [], [] \n",
    "\n",
    "test_query_nums, test_candidate_nums = [], [] \n",
    "\n",
    "query_nums = df[\"쿼리 번호\"].values \n",
    "queries = df[\"쿼리 문장\"].values\n",
    "candidates = df[\"후보 문장\"].values \n",
    "labels = df[\"라벨링\"].values \n",
    "query_document_ids = df[\"쿼리 문서 번호\"].values \n",
    "candidate_document_ids = df[\"Positive 문서 번호\"].values \n",
    "\n",
    "for i in tqdm(range(len(queries)), position=0, leave=True): \n",
    "    if query_nums[i] in train_unique_queries: \n",
    "        train_queries.append(queries[i]) \n",
    "        train_candidates.append(candidates[i]) \n",
    "        train_labels.append(labels[i]) \n",
    "    elif query_nums[i] in val_unique_queries: \n",
    "        valid_queries.append(queries[i]) \n",
    "        valid_candidates.append(candidates[i]) \n",
    "        valid_labels.append(labels[i]) \n",
    "    elif query_nums[i] in test_unique_queries: \n",
    "        test_queries.append(queries[i]) \n",
    "        test_candidates.append(candidates[i]) \n",
    "        test_labels.append(labels[i]) \n",
    "        test_query_nums.append(query_document_ids[i]) \n",
    "        test_candidate_nums.append(candidate_document_ids[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39621450-ad34-4b19-b1d3-07bb4ca09a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DebertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") \n",
    "\n",
    "# load previous checkpoint \n",
    "model = SentenceTransformer(\"../storage/simcse_DEBERTA_KFOLD7\") \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87d41794-4e19-465f-a1e4-0016231005b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(doc_num, L=100):\n",
    "    with open(\"../storage/FGH_spec_ind_claim_triplet_v1.4.1s/\" + str(doc_num) + \".txt\", \"r\") as f: \n",
    "        doc = f.read() \n",
    "    positive_doc = doc.replace(\".\",\";\") \n",
    "    p_ttl = re.search(\"<TTL>([\\s\\S]*?)<IPC>\", positive_doc).group(1)\n",
    "    p_ipc = re.search(\"<IPC>([\\s\\S]*?)<ABST>\", positive_doc).group(1)\n",
    "    p_abst = re.search(\"<ABST>([\\s\\S]*?)<CLMS>\", positive_doc).group(1)\n",
    "    p_clms = re.search(\"<CLMS>([\\s\\S]*?)<DESC>\", positive_doc).group(1)\n",
    "    p_desc = re.search(\"<DESC>([\\s\\S]*)$\", positive_doc).group(1)\n",
    "    splitted_positives = [] \n",
    "    for split in re.split(r\"wherein|[;\\n]+\", p_abst.replace(\".\",\";\")):\n",
    "        if len(split) > L:\n",
    "            splitted_positives.append(split) \n",
    "    for split in re.split(r\"wherein|[;\\n]+\", p_clms.replace(\".\",\";\")):\n",
    "        if len(split) > L:\n",
    "            splitted_positives.append(split) \n",
    "    for split in re.split(r\"wherein|[;\\n]+\", p_desc.replace(\".\",\";\")):\n",
    "        if len(split) > L:\n",
    "            splitted_positives.append(split) \n",
    "    splitted_positives = list(set(splitted_positives))\n",
    "    return splitted_positives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc59ab77-1e47-4ebf-8fe0-f326a162e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only consider unique queries\n",
    "test_queries = np.array(test_queries) \n",
    "_, idx = np.unique(test_queries, return_index=True) \n",
    "unique_test_queries = test_queries[np.sort(idx)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdf4b61b-04df-498b-a70c-be08dfc67d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e10e45086c4d86b59925716360c3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../storage/FGH_spec_ind_claim_triplet_v1.4.1s/20040064166.txt'\n",
      "[Errno 2] No such file or directory: '../storage/FGH_spec_ind_claim_triplet_v1.4.1s/20080200771.txt'\n",
      "[Errno 2] No such file or directory: '../storage/FGH_spec_ind_claim_triplet_v1.4.1s/20030124221.txt'\n",
      "[Errno 2] No such file or directory: '../storage/FGH_spec_ind_claim_triplet_v1.4.1s/20030124221.txt'\n"
     ]
    }
   ],
   "source": [
    "saved_tuples = [] \n",
    "ranks = [] \n",
    "\n",
    "for test_query in tqdm(unique_test_queries, desc=\"Inference\", position=0, leave=True): \n",
    "    search_df = df[df[\"쿼리 문장\"]==test_query] \n",
    "    candidates = search_df[\"후보 문장\"].values \n",
    "    candidate_labels = search_df[\"라벨링\"].values \n",
    "    candidate_doc_num = np.unique(search_df[\"Positive 문서 번호\"]) \n",
    "   \n",
    "    positive_sentence_exists = False \n",
    "    for i in range(len(candidate_labels)): \n",
    "        if candidate_labels[i] >= 0.8: \n",
    "            positive_sentence_exists = True \n",
    "            break\n",
    "    \n",
    "    if positive_sentence_exists == False: \n",
    "        continue # ignore samples that do not have labels at least 0.8 \n",
    "\n",
    "    try: \n",
    "        for doc_num in candidate_doc_num: \n",
    "            splitted_sentences = split_sentences(doc_num) \n",
    "\n",
    "            all_candidates = np.array(candidates.tolist() + splitted_sentences) # force candidates to be in the pool of all splitted sentences, just in case \n",
    "            _, idx = np.unique(all_candidates, return_index=True) # get rid of possible duplicates \n",
    "            all_candidates = all_candidates[np.sort(idx)]\n",
    "\n",
    "            all_labels = candidate_labels.tolist() + [0 for _ in range(len(all_candidates) - len(candidates))] # give zero labels for all sentences not in the gold dataset, regardless of their similarity to the query \n",
    "\n",
    "            all_tuples = [] # query, candidate, gold dataset, score, predicted score \n",
    "            sim_scores = [] \n",
    "            \n",
    "            query_embedding = model.encode(test_query, convert_to_tensor=True)\n",
    "            \n",
    "            # process one by one without any batching -> this part can be modified for potential speedups \n",
    "            for i in range(len(all_candidates)): \n",
    "                candidate_embedding = model.encode(all_candidates[i], convert_to_tensor=True) \n",
    "                cosine_score = util.cos_sim(query_embedding, candidate_embedding) \n",
    "                sim_scores.append(cosine_score.item()) \n",
    "                    \n",
    "            for i in range(len(all_candidates)):\n",
    "                all_tuples.append((test_query, all_candidates[i], all_labels[i], sim_scores[i])) \n",
    "\n",
    "            sorted_list = sorted(all_tuples, key=lambda t: t[3], reverse=True)\n",
    "\n",
    "            rank = 0 \n",
    "            for i in range(len(sorted_list)): \n",
    "                if sorted_list[i][2] >= 0.8: \n",
    "                    rank = i+1 \n",
    "                    break \n",
    "\n",
    "            ranks.append(rank) \n",
    "            saved_tuples.append(sorted_list) \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        continue \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8611416b-7551-4b71-af25-eb50e1f7f160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average rank: 13.051282051282051 \n",
      "\n",
      " MRR@100: 0.6354195615796997 \n",
      "\n",
      " MRR@1000: 0.6355554925822325\n"
     ]
    }
   ],
   "source": [
    "rr = [] \n",
    "for r in ranks:\n",
    "    if r <= 100: \n",
    "        rr.append(1/r)  \n",
    "    else: \n",
    "        rr.append(0)\n",
    "        \n",
    "rr_1000 = [] \n",
    "for r in ranks: \n",
    "    if r <= 1000: \n",
    "        rr_1000.append(1/r) \n",
    "    else:\n",
    "        rr_1000.append(0) \n",
    "\n",
    "print(f\"average rank: {np.mean(ranks)} \\n\\n MRR@100: {np.mean(rr)} \\n\\n MRR@1000: {np.mean(rr_1000)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab24a78b-28e3-47f0-a5a0-bcd3643ee021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"saved_tuples_bi_encoder.pkl\", \"wb\") as f: \n",
    "    pickle.dump(saved_tuples, f) \n",
    "\n",
    "with open(\"saved_ranks_bi_encoder.pkl\", \"wb\") as f: \n",
    "    pickle.dump(ranks, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6bc4170-eba4-4bb2-ba59-5f6415a3276d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.46291381395899"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77668a3d-cb52-4f46-9ce4-19a149a44728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3984d8f-aaff-40c4-891f-2085c7cf3147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
