{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24c57a5-2009-4600-965a-f5b5b39a985d",
   "metadata": {},
   "source": [
    "# Testing our Cross-Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a056938-124b-48c5-bada-7e2594fcc035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 0 files to the new cache system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b5c0a36077426d868b805a68577ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "from tqdm.auto import tqdm \n",
    "from transformers import (\n",
    "    AdamW, \n",
    "    AutoConfig, \n",
    "    AutoModel, \n",
    "    AutoTokenizer, \n",
    "    get_linear_schedule_with_warmup\n",
    ") \n",
    "import torch \n",
    "import torch.nn.functional as F \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler, IterableDataset\n",
    "import math \n",
    "import time \n",
    "import datetime \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1651a765-0b0a-4320-8b69-d11da57bf5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2590216"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(\"../storage/FGH_spec_ind_claim_triplet_v1.4.1s\") \n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "210c63a1-eb3e-411a-bce7-42c11d484efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"0919_라벨링세트_9주차_병합.xlsx\") \n",
    "\n",
    "df = df.loc[df[\"라벨링\"].notnull(), [\"쿼리 번호\", \"IPC 분류\", \"쿼리 문장\", \"후보 문장\", \"쿼리 문서 번호\", \"Positive 문서 번호\", \"라벨링\"]] \n",
    "df = df.dropna() \n",
    "labels_fixed = [] \n",
    "labels = df[\"라벨링\"].values \n",
    "\n",
    "for i in range(len(labels)): \n",
    "    if labels[i] == 0.1: \n",
    "        labels_fixed.append(1.0) \n",
    "    elif labels[i] not in [0, 0.5, 0.8, 1.0]: \n",
    "        labels_fixed.append(None) \n",
    "    else: \n",
    "        labels_fixed.append(labels[i]) \n",
    "\n",
    "df[\"라벨링\"] = labels_fixed \n",
    "df = df.dropna() \n",
    "query_numbers = df[\"쿼리 번호\"].values \n",
    "unique_queries = np.unique(query_numbers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f8ee389-de4f-4179-829f-5eb27280281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(unique_queries) * 0.8) \n",
    "val_size = int(len(unique_queries) * 0.1) \n",
    "\n",
    "train_unique_queries = unique_queries[:train_size] \n",
    "val_unique_queries = unique_queries[train_size:train_size+val_size] \n",
    "test_unique_queries = unique_queries[train_size+val_size:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a64ec17c-1884-41cd-8652-d76e8f09bfb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e6060d898e4ff1a4b7e21021dea83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_queries, train_candidates, train_labels = [], [], [] \n",
    "valid_queries, valid_candidates, valid_labels = [], [], [] \n",
    "test_queries, test_candidates, test_labels = [], [], [] \n",
    "\n",
    "test_query_nums, test_candidate_nums = [], [] \n",
    "\n",
    "query_nums = df[\"쿼리 번호\"].values \n",
    "queries = df[\"쿼리 문장\"].values\n",
    "candidates = df[\"후보 문장\"].values \n",
    "labels = df[\"라벨링\"].values \n",
    "query_document_ids = df[\"쿼리 문서 번호\"].values \n",
    "candidate_document_ids = df[\"Positive 문서 번호\"].values \n",
    "\n",
    "for i in tqdm(range(len(queries)), position=0, leave=True): \n",
    "    if query_nums[i] in train_unique_queries: \n",
    "        train_queries.append(queries[i]) \n",
    "        train_candidates.append(candidates[i]) \n",
    "        train_labels.append(labels[i]) \n",
    "    elif query_nums[i] in val_unique_queries: \n",
    "        valid_queries.append(queries[i]) \n",
    "        valid_candidates.append(candidates[i]) \n",
    "        valid_labels.append(labels[i]) \n",
    "    elif query_nums[i] in test_unique_queries: \n",
    "        test_queries.append(queries[i]) \n",
    "        test_candidates.append(candidates[i]) \n",
    "        test_labels.append(labels[i]) \n",
    "        test_query_nums.append(query_document_ids[i]) \n",
    "        test_candidate_nums.append(candidate_document_ids[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a38403d-3a95-4e60-a2de-ee011ec07297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tanapatentlm/patentdeberta_large_spec_128_pwi were not used when initializing DebertaModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"tanapatentlm/patentdeberta_large_spec_128_pwi\") \n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# define model \n",
    "class WeightedLayerPooling(nn.Module): \n",
    "    def __init__(self, num_hidden_layers, layer_start, layer_weights=None): \n",
    "        super(WeightedLayerPooling, self).__init__() \n",
    "        self.layer_start = layer_start \n",
    "        self.num_hidden_layers = num_hidden_layers \n",
    "        self.layer_weights = nn.Parameter(torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)) \n",
    "    def forward(self, all_hidden_states): \n",
    "        all_layer_embedding = torch.stack(list(all_hidden_states), dim=0) \n",
    "        all_layer_embedding = all_layer_embedding[self.layer_start:, :, :, :] \n",
    "        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n",
    "        weighted_average = (weight_factor * all_layer_embedding).sum(dim=0) / self.layer_weights.sum()  \n",
    "        return weighted_average \n",
    "\n",
    "class SentenceRanker(nn.Module): \n",
    "    def __init__(self, plm=\"tanapatentlm/patentdeberta_large_spec_128_pwi\"): \n",
    "        super(SentenceRanker, s 314/843 [02:45<04:38, 1.90batch/s, loss=0.00266]elf).__init__() \n",
    "        self.config = AutoConfig.from_pretrained(plm) \n",
    "        self.config.hidden_dropout = 0 \n",
    "        self.config.hidden_dropout_prob = 0 \n",
    "        self.config.attention_dropout = 0 \n",
    "        self.config.attention_probs_dropout_prob = 0 \n",
    "        self.model = AutoModel.from_pretrained(plm, config=self.config) \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(plm) \n",
    "        self.weighted_layer_pooling = WeightedLayerPooling(self.config.num_hidden_layers, 6, None) \n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1) \n",
    "        self._init_weights(self.fc) \n",
    "    \n",
    "    def _init_weights(self, module): \n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None: \n",
    "                module.bias.data.zero_() \n",
    "        elif isinstance(module, nn.Embedding): \n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None: \n",
    "                module.weight.data[module.padding_idx].zero_() \n",
    "        elif isinstance(module, nn.LayerNorm): \n",
    "            module.bias.data.zero_() \n",
    "            module.weight.data.fill_(1.0) \n",
    "    \n",
    "    def forward(self, input_ids, attn_masks): \n",
    "        x = self.model(input_ids, attn_masks, output_hidden_states=True)\n",
    "        x = self.weighted_layer_pooling(x.hidden_states) \n",
    "        x = x[:, 0] \n",
    "        x = self.fc(x) \n",
    "        return x \n",
    "    \n",
    "    \n",
    "# load preModifiedvious checkpoint \n",
    "checkpoint = \"M_DeBERTa_Cross_Encoder_0.033700802607199876.pt\"\n",
    "model = SentenceRanker() \n",
    "checkpoint = torch.load(checkpoint) \n",
    "model.load_state_dict(checkpoint) \n",
    "model.cuda() \n",
    "model.eval() \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7151faef-4dce-42b1-b036-f226dd1dc5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(doc_num, L=100):\n",
    "    with open(\"../storage/FGH_spec_ind_claim_triplet_v1.4.1s/\" + str(doc_num) + \".txt\", \"r\") as f: \n",
    "        doc = f.read() \n",
    "    positive_doc = doc.replace(\".\",\";\") \n",
    "    p_ttl = re.search(\"<TTL>([\\s\\S]*?)<IPC>\", positive_doc).group(1)\n",
    "    p_ipc = re.search(\"<IPC>([\\s\\S]*?)<ABST>\", positive_doc).group(1)\n",
    "    p_abst = re.search(\"<ABST>([\\s\\S]*?)<CLMS>\", positive_doc).group(1)\n",
    "    p_clms = re.search(\"<CLMS>([\\s\\S]*?)<DESC>\", positive_doc).group(1)\n",
    "    p_desc = re.search(\"<DESC>([\\s\\S]*)$\", positive_doc).group(1)\n",
    "    splitted_positives = [] \n",
    "    for split in re.split(r\"wherein|[;\\n]+\", p_abst.replace(\".\",\";\")):\n",
    "        if len(split) > L:\n",
    "            splitted_positives.append(split) \n",
    "    for split in re.split(r\"wherein|[;\\n]+\", p_clms.replace(\".\",\";\")):\n",
    "        if len(split) > L:\n",
    "            splitted_positives.append(split) \n",
    "    for split in re.split(r\"wherein|[;\\n]+\", p_desc.replace(\".\",\";\")):\n",
    "        if len(split) > L:\n",
    "            splitted_positives.append(split) \n",
    "    splitted_positives = list(set(splitted_positives))\n",
    "    return splitted_positives \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b50fe509-d0fe-44b7-95e4-ca7beba93cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only consider unique queries\n",
    "test_queries = np.array(test_queries) \n",
    "_, idx = np.unique(test_queries, return_index=True) \n",
    "unique_test_queries = test_queries[np.sort(idx)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "729dee5f-2e6d-416d-a9a2-0d98ec1d691a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b4e0e9974a40c583bf036762e5ead9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../storage/FGH_spec_ind_claim_triplet_v1.4.1s/20040064166.txt'\n",
      "[Errno 2] No such file or directory: '../storage/FGH_spec_ind_claim_triplet_v1.4.1s/20080200771.txt'\n",
      "[Errno 2] No such file or directory: '../storage/FGH_spec_ind_claim_triplet_v1.4.1s/20030124221.txt'\n",
      "[Errno 2] No such file or directory: '../storage/FGH_spec_ind_claim_triplet_v1.4.1s/20030124221.txt'\n"
     ]
    }
   ],
   "source": [
    "saved_tuples = [] \n",
    "ranks = [] \n",
    "\n",
    "for test_query in tqdm(unique_test_queries, desc=\"Inference\", position=0, leave=True): \n",
    "    search_df = df[df[\"쿼리 문장\"]==test_query] \n",
    "    candidates = search_df[\"후보 문장\"].values \n",
    "    candidate_labels = search_df[\"라벨링\"].values \n",
    "    candidate_doc_num = np.unique(search_df[\"Positive 문서 번호\"]) \n",
    "   \n",
    "    positive_sentence_exists = False \n",
    "    for i in range(len(candidate_labels)): \n",
    "        if candidate_labels[i] >= 0.8: \n",
    "            positive_sentence_exists = True \n",
    "            break\n",
    "    \n",
    "    if positive_sentence_exists == False: \n",
    "        continue # ignore samples that do not have labels at least 0.8 \n",
    "\n",
    "    try: \n",
    "        for doc_num in candidate_doc_num: \n",
    "            splitted_sentences = split_sentences(doc_num) \n",
    "\n",
    "            all_candidates = np.array(candidates.tolist() + splitted_sentences) # force candidates to be in the pool of all splitted sentences, just in case \n",
    "            _, idx = np.unique(all_candidates, return_index=True) # get rid of possible duplicates \n",
    "            all_candidates = all_candidates[np.sort(idx)]\n",
    "\n",
    "            all_labels = candidate_labels.tolist() + [0 for _ in range(len(all_candidates) - len(candidates))] # give zero labels for all sentences not in the gold dataset, regardless of their similarity to the query \n",
    "\n",
    "            all_tuples = [] # query, candidate, gold dataset, score, predicted score \n",
    "            sim_scores = [] \n",
    "\n",
    "            # process one by one without any batching -> this part can be modified for potential speedups \n",
    "            for i in range(len(all_candidates)): \n",
    "                encoded_input = tokenizer(test_query, all_candidates[i], max_length=256, truncation=True, padding=\"max_length\", return_tensors=\"pt\").to(device) \n",
    "                input_ids = encoded_input[\"input_ids\"] \n",
    "                attn_masks = encoded_input[\"attention_mask\"] \n",
    "                with torch.no_grad(): \n",
    "                    output = model(input_ids, attn_masks) \n",
    "                sim_scores.append(output.item()) \n",
    "\n",
    "            for i in range(len(all_candidates)):\n",
    "                all_tuples.append((test_query, all_candidates[i], all_labels[i], sim_scores[i])) \n",
    "\n",
    "            sorted_list = sorted(all_tuples, key=lambda t: t[3], reverse=True)\n",
    "\n",
    "            rank = 0 \n",
    "            for i in range(len(sorted_list)): \n",
    "                if sorted_list[i][2] >= 0.8: \n",
    "                    rank = i+1 \n",
    "                    break \n",
    "\n",
    "            ranks.append(rank) \n",
    "            saved_tuples.append(sorted_list) \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        continue \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e650877d-8058-4711-ad49-e28c1eede5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average rank: 14.0 \n",
      "\n",
      " MRR@100: 0.46898411543695884 \n",
      "\n",
      " MRR@1000: 0.4694485382038454\n"
     ]
    }
   ],
   "source": [
    "rr = [] \n",
    "for r in ranks:\n",
    "    if r <= 100: \n",
    "        rr.append(1/r)  \n",
    "    else: \n",
    "        rr.append(0)\n",
    "        \n",
    "rr_1000 = [] \n",
    "for r in ranks: \n",
    "    if r <= 1000: \n",
    "        rr_1000.append(1/r) \n",
    "    else:\n",
    "        rr_1000.append(0) \n",
    "\n",
    "print(f\"average rank: {np.mean(ranks)} \\n\\n MRR@100: {np.mean(rr)} \\n\\n MRR@1000: {np.mean(rr_1000)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68a7eaa9-b493-4311-ab73-d8e1aac3077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"saved_tuples_cross_encoder.pkl\", \"wb\") as f: \n",
    "    pickle.dump(saved_tuples, f) \n",
    "\n",
    "with open(\"saved_ranks_cross_encoder.pkl\", \"wb\") as f: \n",
    "    pickle.dump(ranks, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b652597e-d004-478c-a70d-958304c76cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.065921424627362"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d4955-79dc-48ba-950f-0c53fd3a14fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c05c71d-a475-4475-b89f-be59ae520e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
