{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ff356ae-e3e9-4bbf-aef0-077a386379ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "from tqdm.auto import tqdm \n",
    "from transformers import (\n",
    "    AdamW, \n",
    "    AutoConfig, \n",
    "    AutoModel, \n",
    "    AutoTokenizer, \n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler, IterableDataset \n",
    "import math \n",
    "import time \n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a71796c-7565-4740-aa27-c687f21c3c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2590216"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(\"../storage/FGH_spec_ind_claim_triplet_v1.4.1s\") \n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0783042f-3524-4f51-bf91-e52983c00497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"0919_라벨링세트_9주차_병합.xlsx\") \n",
    "\n",
    "df = df.loc[df[\"라벨링\"].notnull(), [\"쿼리 번호\", \"IPC 분류\", \"쿼리 문장\", \"후보 문장\", \"쿼리 문서 번호\", \"Positive 문서 번호\", \"라벨링\"]] \n",
    "df = df.dropna() \n",
    "labels_fixed = [] \n",
    "labels = df[\"라벨링\"].values \n",
    "\n",
    "for i in range(len(labels)): \n",
    "    if labels[i] == 0.1: \n",
    "        labels_fixed.append(1.0) \n",
    "    elif labels[i] not in [0, 0.5, 0.8, 1.0]: \n",
    "        labels_fixed.append(None) \n",
    "    else: \n",
    "        labels_fixed.append(labels[i]) \n",
    "\n",
    "df[\"라벨링\"] = labels_fixed \n",
    "df = df.dropna() \n",
    "query_numbers = df[\"쿼리 번호\"].values \n",
    "unique_queries = np.unique(query_numbers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "175c6d5f-7560-4e0e-b90b-36af5b9357bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(unique_queries) * 0.8) \n",
    "val_size = int(len(unique_queries) * 0.1) \n",
    "\n",
    "train_unique_queries = unique_queries[:train_size] \n",
    "val_unique_queries = unique_queries[train_size:train_size+val_size] \n",
    "test_unique_queries = unique_queries[train_size+val_size:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7289f1f-4fe8-46d1-ab00-b453cb40d05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>쿼리 번호</th>\n",
       "      <th>IPC 분류</th>\n",
       "      <th>쿼리 문장</th>\n",
       "      <th>후보 문장</th>\n",
       "      <th>쿼리 문서 번호</th>\n",
       "      <th>Positive 문서 번호</th>\n",
       "      <th>라벨링</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>F21V504</td>\n",
       "      <td>an adjustable lens positioned so as to alter ...</td>\n",
       "      <td>Several mechanisms for altering the beam prod...</td>\n",
       "      <td>20080259600</td>\n",
       "      <td>6474837</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>F21V504</td>\n",
       "      <td>an adjustable lens positioned so as to alter ...</td>\n",
       "      <td>When a plurality of aperture plates are incor...</td>\n",
       "      <td>20080259600</td>\n",
       "      <td>6474837</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   쿼리 번호   IPC 분류                                              쿼리 문장  \\\n",
       "0    166  F21V504   an adjustable lens positioned so as to alter ...   \n",
       "1    166  F21V504   an adjustable lens positioned so as to alter ...   \n",
       "\n",
       "                                               후보 문장     쿼리 문서 번호  \\\n",
       "0   Several mechanisms for altering the beam prod...  20080259600   \n",
       "1   When a plurality of aperture plates are incor...  20080259600   \n",
       "\n",
       "  Positive 문서 번호  라벨링  \n",
       "0        6474837  0.8  \n",
       "1        6474837  0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfae1a11-1522-4c9f-b82d-08ef4f6d16fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['쿼리 번호', 'IPC 분류', '쿼리 문장', '후보 문장', '쿼리 문서 번호', 'Positive 문서 번호',\n",
       "       '라벨링'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50da0b6a-2f43-4670-a233-53ab1c25f2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d4a1f31d7f4e1b8330ec245c33178b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_queries, train_candidates, train_labels = [], [], [] \n",
    "valid_queries, valid_candidates, valid_labels = [], [], [] \n",
    "test_queries, test_candidates, test_labels = [], [], [] \n",
    "\n",
    "test_query_nums, test_candidate_nums = [], [] \n",
    "\n",
    "query_nums = df[\"쿼리 번호\"].values \n",
    "queries = df[\"쿼리 문장\"].values\n",
    "candidates = df[\"후보 문장\"].values \n",
    "labels = df[\"라벨링\"].values \n",
    "query_document_ids = df[\"쿼리 문서 번호\"].values \n",
    "candidate_document_ids = df[\"Positive 문서 번호\"].values \n",
    "\n",
    "for i in tqdm(range(len(queries)), position=0, leave=True): \n",
    "    if query_nums[i] in train_unique_queries: \n",
    "        train_queries.append(queries[i]) \n",
    "        train_candidates.append(candidates[i]) \n",
    "        train_labels.append(labels[i]) \n",
    "    elif query_nums[i] in val_unique_queries: \n",
    "        valid_queries.append(queries[i]) \n",
    "        valid_candidates.append(candidates[i]) \n",
    "        valid_labels.append(labels[i]) \n",
    "    elif query_nums[i] in test_unique_queries: \n",
    "        test_queries.append(queries[i]) \n",
    "        test_candidates.append(candidates[i]) \n",
    "        test_labels.append(labels[i]) \n",
    "        test_query_nums.append(query_document_ids[i]) \n",
    "        test_candidate_nums.append(candidate_document_ids[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ee1d544-c4ad-46e7-9305-7a1e2445961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"tanapatentlm/patentdeberta_large_spec_128_pwi\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6dcf877-94a1-4565-a8c2-9c3f667d2957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedLayerPooling(nn.Module): \n",
    "    def __init__(self, num_hidden_layers, layer_start, layer_weights=None): \n",
    "        super(WeightedLayerPooling, self).__init__() \n",
    "        self.layer_start = layer_start \n",
    "        self.num_hidden_layers = num_hidden_layers \n",
    "        self.layer_weights = nn.Parameter(torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)) \n",
    "    def forward(self, all_hidden_states): \n",
    "        all_layer_embedding = torch.stack(list(all_hidden_states), dim=0) \n",
    "        all_layer_embedding = all_layer_embedding[self.layer_start:, :, :, :] \n",
    "        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n",
    "        weighted_average = (weight_factor * all_layer_embedding).sum(dim=0) / self.layer_weights.sum()  \n",
    "        return weighted_average \n",
    "\n",
    "class SentenceRanker(nn.Module): \n",
    "    def __init__(self, plm=\"tanapatentlm/patentdeberta_large_spec_128_pwi\"): \n",
    "        super(SentenceRanker, self).__init__() \n",
    "        self.config = AutoConfig.from_pretrained(plm) \n",
    "        self.config.hidden_dropout = 0 \n",
    "        self.config.hidden_dropout_prob = 0 \n",
    "        self.config.attention_dropout = 0 \n",
    "        self.config.attention_probs_dropout_prob = 0 \n",
    "        self.net = AutoModel.from_pretrained(plm, config=self.config) \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(plm) \n",
    "        self.tokenizer.add_special_tokens({\"additional_special_tokens\":[\"[IPC]\", \"[TTL]\", \"[CLMS]\", \"[ABST]\"]}) \n",
    "        self.net.resize_token_embeddings(len(self.tokenizer)) \n",
    "        self.weighted_layer_pooling = WeightedLayerPooling(self.config.num_hidden_layers, 6, None) \n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1) \n",
    "        self._init_weights(self.fc) \n",
    "    \n",
    "    def _init_weights(self, module): \n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None: \n",
    "                module.bias.data.zero_() \n",
    "        elif isinstance(module, nn.Embedding): \n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None: \n",
    "                module.weight.data[module.padding_idx].zero_() \n",
    "        elif isinstance(module, nn.LayerNorm): \n",
    "            module.bias.data.zero_() \n",
    "            module.weight.data.fill_(1.0) \n",
    "    \n",
    "    def forward(self, input_ids, attn_masks): \n",
    "        x = self.net(input_ids, attn_masks, output_hidden_states=True)\n",
    "        x = self.weighted_layer_pooling(x.hidden_states) \n",
    "        x = x[:, 0] \n",
    "        x = self.fc(x) \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db619e65-77c2-4fbd-b64f-7638bcaaaade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tanapatentlm/patentdeberta_large_spec_128_pwi were not used when initializing DebertaModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = SentenceRanker() \n",
    "model.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7086de9-03f9-4479-a2de-65ac2aa0ad9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# transfer learning \n",
    "ckpt = \"../storage/epoch_end_checkpoints-epoch=00-val_loss=0.20442404.ckpt\" \n",
    "checkpoint = torch.load(ckpt) \n",
    "new_weights = model.state_dict() \n",
    "old_weights = list(checkpoint[\"state_dict\"].items()) \n",
    "for j in range(len(old_weights)): \n",
    "    new_weights[old_weights[j][0]] = old_weights[j][1] \n",
    "print(model.load_state_dict(new_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9150f904-cedc-4759-8613-3fd5e92cacab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b46832b72d4146a3d85089d0afee5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26947 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb7799bbe8a4aa69f4b3384eb7ab48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3060 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26947, 256]) torch.Size([26947, 256]) torch.Size([26947, 1]) torch.Size([3060, 256]) torch.Size([3060, 256]) torch.Size([3060, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28389/1418897610.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels).float()\n",
      "/tmp/ipykernel_28389/1418897610.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_labels = torch.tensor(valid_labels).float()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec8f8a9976f49ee97fe4d00df95a469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09849111196844a6b3bba94a679864fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.01052044426637325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0040698222b40ff8712e8aad176ca93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average validation loss : 0.03465540017108045\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea452900c9642dfa09e3bf5206bd798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.009046979622765138\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37ebaea938c43c29fa98817e2270401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average validation loss : 0.03713473094103392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d34558863f046ec983efcf6ec15c19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.0061002446640689425\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60485990fc1340b69c1eb6da846f9890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average validation loss : 0.03787937156175758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6153ad2ca55648868b95683192989a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.004337847244971093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f69dfc637e430386ede700e3e688a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average validation loss : 0.04044487747402551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5638de2f5f384c6b964150b72884f361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.0030240793149003565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d9cb515ed74aa590bc689c2210fb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average validation loss : 0.03772842030836424\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af221e890d1342edaa2afb61b69e0284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.0021756847254242964\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a1fd0db37c4e0f8ca2ef2e54efd317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average validation loss : 0.03614244644995779\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a503e3369646b883e3ec05e714c0c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.0016182212966194178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde055a6cad44c12ab42db2e713afec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average validation loss : 0.037259216374271396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8915e74387641c6ad73789726674c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.0012974387577984912\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645f928679044fde8a21da34baacc2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average validation loss : 0.037801968050189316\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950ce52f1ed94a459358d11896b2a441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.0011131044573443063\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bedb431fe9af4d1480613a770f9d1a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average validation loss : 0.03819194790654971\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1829f68e924af2868d5bf5c96f9933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 0.0010246235364814581\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a105ca55624d3ab6b7c88e4d3d8259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average validation loss : 0.0382451373928537\n"
     ]
    }
   ],
   "source": [
    "train_input_ids, train_attn_masks = [], [] \n",
    "valid_input_ids, valid_attn_masks = [], [] \n",
    "\n",
    "max_len = 256 # 512 \n",
    "\n",
    "for i in tqdm(range(len(train_queries)), position=0, leave=True): \n",
    "    encoded_input = tokenizer(train_queries[i], train_candidates[i], max_length=max_len, truncation=True, padding=\"max_length\") \n",
    "    train_input_ids.append(encoded_input[\"input_ids\"]) \n",
    "    train_attn_masks.append(encoded_input[\"attention_mask\"]) \n",
    "\n",
    "for i in tqdm(range(len(valid_queries)), position=0, leave=True): \n",
    "    encoded_input = tokenizer(valid_queries[i], valid_candidates[i], max_length=max_len, truncation=True, padding=\"max_length\") \n",
    "    valid_input_ids.append(encoded_input[\"input_ids\"])\n",
    "    valid_attn_masks.append(encoded_input[\"attention_mask\"]) \n",
    "    \n",
    "train_input_ids = torch.tensor(train_input_ids, dtype=int) \n",
    "train_attn_masks = torch.tensor(train_attn_masks, dtype=int) \n",
    "train_labels = torch.tensor(train_labels).float() \n",
    "train_labels = torch.reshape(train_labels, (-1,1)) \n",
    "\n",
    "valid_input_ids = torch.tensor(valid_input_ids, dtype=int) \n",
    "valid_attn_masks = torch.tensor(valid_attn_masks, dtype=int) \n",
    "valid_labels = torch.tensor(valid_labels).float() \n",
    "valid_labels = torch.reshape(valid_labels, (-1,1)) \n",
    "\n",
    "print(train_input_ids.shape, train_attn_masks.shape, train_labels.shape, valid_input_ids.shape, valid_attn_masks.shape, valid_labels.shape)\n",
    "\n",
    "batch_size = 32 #24\n",
    "\n",
    "train_data = TensorDataset(train_input_ids, train_attn_masks, train_labels) \n",
    "train_sampler = RandomSampler(train_data) \n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size) \n",
    "\n",
    "val_data = TensorDataset(valid_input_ids, valid_attn_masks, valid_labels) \n",
    "val_sampler = SequentialSampler(val_data) \n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size) \n",
    "\n",
    "val_losses = [] \n",
    "\n",
    "loss_func = nn.SmoothL1Loss() \n",
    "model.cuda() \n",
    "optimizer = AdamW(model.parameters(), lr=2e-5) \n",
    "epochs = 10\n",
    "total_steps = len(train_dataloader) * epochs \n",
    "'''\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=100,\n",
    "                                            num_training_steps=total_steps) \n",
    "''' \n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0, \n",
    "                                            num_training_steps=total_steps, \n",
    "                                            num_cycles=0.5) \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") \n",
    "model.zero_grad() \n",
    "for epcoh_i in tqdm(range(0, epochs), desc=\"Epochs\", position=0, leave=True, total=epochs): \n",
    "    train_loss = 0 \n",
    "    model.train() \n",
    "    with tqdm(train_dataloader, unit=\"batch\") as tepoch: \n",
    "        for step, batch in enumerate(tepoch): \n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_masks, b_labels = batch \n",
    "            outputs = model(b_input_ids, b_input_masks) \n",
    "            loss = loss_func(outputs, b_labels) \n",
    "            train_loss += loss.item() \n",
    "            loss.backward() \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) \n",
    "            optimizer.step() \n",
    "            scheduler.step() \n",
    "            model.zero_grad() \n",
    "            tepoch.set_postfix(loss=train_loss / (step+1)) \n",
    "            time.sleep(0.1) \n",
    "    avg_train_loss = train_loss / len(train_dataloader) \n",
    "    print(f\"average train loss : {avg_train_loss}\")\n",
    "    \n",
    "    val_loss = 0 \n",
    "    model.eval() \n",
    "    for step, batch in tqdm(enumerate(val_dataloader), desc=\"Validating\", position=0, leave=True, total=len(val_dataloader)): \n",
    "        batch = tuple(t.to(device) for t in batch) \n",
    "        b_input_ids, b_input_masks, b_labels = batch \n",
    "        with torch.no_grad(): \n",
    "            outputs = model(b_input_ids, b_input_masks) \n",
    "        loss = loss_func(outputs, b_labels) \n",
    "        val_loss += loss.item() \n",
    "    avg_val_loss = val_loss / len(val_dataloader) \n",
    "    print(f\"average validation loss : {avg_val_loss}\") \n",
    "    val_losses.append(avg_val_loss) \n",
    "    \n",
    "    if np.min(val_losses) == val_losses[-1]:\n",
    "        torch.save(model.state_dict(), f\"M4_DeBERTa_Cross_Encoder_{avg_val_loss}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b8d66-3640-45d8-9683-627467e9a718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d57e3-2ade-4d39-b497-8ad60e6209d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d19687-a1f6-4a68-a397-62590edd792a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d897795-c753-4548-b419-46e55fd412ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f1612-9c2e-4ae8-99e3-d05a2cba8c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc5cfab-6585-4ed3-a6e7-61d5f025a9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b857e5-c044-4842-83e3-30c9d6752771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9da57f2-92f2-4856-8e3e-4c09aed1afd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b465df70-945d-4fa2-b735-2daaf59205eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4612729-ef22-48e1-b83b-d14c06a395cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e121bf8-a717-49c8-aaa7-4b3b8af7987e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd17b2d-3d08-48de-979d-f537739da9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
