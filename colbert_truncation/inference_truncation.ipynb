{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import string \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from transformers import BertPreTrainedModel, BertModel, BertTokenizerFast, AdamW\n",
    "from colbert.parameters import DEVICE \n",
    "import os \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colbert-30000.dnn',\n",
       " 'colbert-32000.dnn',\n",
       " 'colbert.dnn',\n",
       " 'colbert-10000.dnn',\n",
       " 'colbert-20000.dnn',\n",
       " 'colbert-25000.dnn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check saved checkpoints \n",
    "os.listdir('experiments/dirty/train.py/2021-12-06_08.01.48/checkpoints/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Indexes For Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 False 64\n",
      "\n",
      "\n",
      "[Dec 07, 02:43:29] #> Creating directory /workspace/patent_similarity/ColBERT/experiments/dirty/index.py/2021-12-07_02.43.21 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Dec 07, 02:43:29] #> Creating directory /workspace/patent_similarity/ColBERT/experiments/dirty/index.py/2021-12-07_02.43.21/logs/ \n",
      "\n",
      "\n",
      "[Dec 07, 02:43:29] {'root': 'experiments', 'experiment': 'dirty', 'run': '2021-12-07_02.43.21', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 512, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': './experiments/dirty/train.py/2021-12-06_08.01.48/checkpoints/colbert-32000.dnn', 'bsize': 256, 'amp': True, 'collection': 'test_collections.tsv', 'index_root': './experiments/indexes', 'index_name': 'large_train_index', 'chunksize': 6.0} \n",
      "\n",
      "\n",
      "\n",
      "[Dec 07, 02:43:29] #> Note: Output directory ./experiments/indexes already exists\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Dec 07, 02:43:29] #> Creating directory ./experiments/indexes/large_train_index \n",
      "\n",
      "\n",
      "[Dec 07, 02:43:29] [0] \t\t #> Local args.bsize = 256\n",
      "[Dec 07, 02:43:29] [0] \t\t #> args.index_root = ./experiments/indexes\n",
      "[Dec 07, 02:43:29] [0] \t\t #> self.possible_subset_sizes = [49152]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[Dec 07, 02:43:40] #> Loading model checkpoint.\n",
      "[Dec 07, 02:43:40] #> Loading checkpoint ./experiments/dirty/train.py/2021-12-06_08.01.48/checkpoints/colbert-32000.dnn ..\n",
      "[Dec 07, 02:43:41] #> checkpoint['epoch'] = 0\n",
      "[Dec 07, 02:43:41] #> checkpoint['batch'] = 32000\n",
      "{\n",
      "    \"root\": \"experiments\",\n",
      "    \"experiment\": \"dirty\",\n",
      "    \"run\": \"2021-12-06_08.01.48\",\n",
      "    \"rank\": -1,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"dim\": 128,\n",
      "    \"query_maxlen\": 512,\n",
      "    \"doc_maxlen\": 512,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"resume\": false,\n",
      "    \"resume_optimizer\": false,\n",
      "    \"checkpoint\": null,\n",
      "    \"lr\": 3e-6,\n",
      "    \"maxsteps\": 400000,\n",
      "    \"bsize\": 8,\n",
      "    \"accumsteps\": 4,\n",
      "    \"amp\": true,\n",
      "    \"triples\": \"train_df.tsv\",\n",
      "    \"queries\": null,\n",
      "    \"collection\": null\n",
      "}\n",
      "\n",
      "\n",
      "[Dec 07, 02:48:28] [0] \t\t #> Completed batch #0 (starting at passage #0) \t\tPassages/min: 10.4k (overall),  10.4k (this encoding),  22864.2M (this saving)\n",
      "[Dec 07, 02:48:44] [0] \t\t #> Saved batch #0 to ./experiments/indexes/large_train_index/0.pt \t\t Saving Throughput = 185.0k passages per minute.\n",
      "\n",
      "[Dec 07, 02:51:17] [0] \t\t #> Completed batch #1 (starting at passage #49152) \t\tPassages/min: 10.3k (overall),  10.7k (this encoding),  16623.9M (this saving)\n",
      "[Dec 07, 02:51:17] [0] \t\t [NOTE] Done with local share.\n",
      "[Dec 07, 02:51:17] [0] \t\t #> Joining saver thread.\n",
      "[Dec 07, 02:51:24] [0] \t\t #> Saved batch #1 to ./experiments/indexes/large_train_index/1.pt \t\t Saving Throughput = 253.3k passages per minute.\n",
      "\n",
      "[Dec 07, 02:51:24] Saving (the following) metadata to ./experiments/indexes/large_train_index/metadata.json ..\n",
      "Namespace(amp=True, bsize=256, checkpoint='./experiments/dirty/train.py/2021-12-06_08.01.48/checkpoints/colbert-32000.dnn', chunksize=6.0, collection='test_collections.tsv', dim=128, doc_maxlen=512, experiment='dirty', index_name='large_train_index', index_root='./experiments/indexes', mask_punctuation=True, query_maxlen=512, rank=-1, root='experiments', run='2021-12-07_02.43.21', similarity='cosine')\n"
     ]
    }
   ],
   "source": [
    "!python -m colbert.index --amp --doc_maxlen 512 --query_maxlen 512 \\\n",
    "--mask-punctuation --bsize 256 --checkpoint ./experiments/dirty/train.py/2021-12-06_08.01.48/checkpoints/colbert-32000.dnn \\\n",
    "--collection test_collections.tsv --index_root ./experiments/indexes --index_name large_train_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS Indexing for End-To-End Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 False 64\n",
      "\n",
      "\n",
      "[Dec 07, 02:54:47] #> Creating directory /workspace/patent_similarity/ColBERT/experiments/dirty/index_faiss.py/2021-12-07_02.54.47 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Dec 07, 02:54:47] #> Creating directory /workspace/patent_similarity/ColBERT/experiments/dirty/index_faiss.py/2021-12-07_02.54.47/logs/ \n",
      "\n",
      "\n",
      "[Dec 07, 02:54:47] {'root': 'experiments', 'experiment': 'dirty', 'run': '2021-12-07_02.54.47', 'rank': -1, 'index_root': './experiments/indexes', 'index_name': 'large_train_index', 'partitions': None, 'sample': None, 'slices': 1} \n",
      "\n",
      "#> num_embeddings = 38915192\n",
      "\n",
      "\n",
      "\n",
      "[Dec 07, 02:54:47] [WARNING] \t You did not specify --partitions!\n",
      "[Dec 07, 02:54:47] [WARNING] \t Default computation chooses 65536 partitions (for 38915192 embeddings)\n",
      "\n",
      "\n",
      "\n",
      "[Dec 07, 02:54:47] #> Starting..\n",
      "[Dec 07, 02:54:47] #> Processing slice #1 of 1 (range 0..2).\n",
      "[Dec 07, 02:54:47] #> Will write to ./experiments/indexes/large_train_index/ivfpq.65536.faiss.\n",
      "[Dec 07, 02:54:47] #> Loading ./experiments/indexes/large_train_index/0.sample ...\n",
      "[Dec 07, 02:54:47] #> Loading ./experiments/indexes/large_train_index/1.sample ...\n",
      "#> Sample has shape (1945759, 128)\n",
      "[Dec 07, 02:54:53] Preparing resources for 1 GPUs.\n",
      "[Dec 07, 02:54:53] #> Training with the vectors...\n",
      "[Dec 07, 02:54:53] #> Training now (using 1 GPUs)...\n",
      "130.09617686271667\n",
      "WARNING clustering 1945759 points to 65536 centroids: please provide at least 2555904 training points\n",
      "123.43501019477844\n",
      "0.021433115005493164\n",
      "[Dec 07, 02:59:07] Done training!\n",
      "\n",
      "[Dec 07, 02:59:07] #> Indexing the vectors...\n",
      "[Dec 07, 02:59:07] #> Loading ('./experiments/indexes/large_train_index/0.pt', './experiments/indexes/large_train_index/1.pt', None) (from queue)...\n",
      "[Dec 07, 02:59:18] #> Processing a sub_collection with shape (38915192, 128)\n",
      "[Dec 07, 02:59:18] Add data with shape (38915192, 128) (offset = 0)..\n",
      "  IndexIVFPQ size 0 -> GpuIndexIVFPQ indicesOptions=0 usePrecomputed=0 useFloat16=1 reserveVecs=33554432\n",
      "33488896/38915192 (259.193 s)   Flush indexes to CPU\n",
      "38862848/38915192 (298.509 s)   Flush indexes to CPU\n",
      "add(.) time: 301.624 s \t\t--\t\t index.ntotal = 38915192\n",
      "[Dec 07, 03:04:20] Done indexing!\n",
      "[Dec 07, 03:04:20] Writing index to ./experiments/indexes/large_train_index/ivfpq.65536.faiss ...\n",
      "[Dec 07, 03:04:21] \n",
      "\n",
      "Done! All complete (for slice #1 of 1)!\n"
     ]
    }
   ],
   "source": [
    "!python -m colbert.index_faiss --index_root ./experiments/indexes --index_name large_train_index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve and ReRank\n",
    "\n",
    "There are 77886 documents in the corpus. \n",
    "\n",
    "There are 38943 queries. We test with a smaller query size (first 100 and first 500 respectively) due to time and memory constraints. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>queries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A system for charging or maintaining a batter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A method for calculating a path delay in stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A preventive or therapeutic agent for diabete...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            queries\n",
       "0   0   A system for charging or maintaining a batter...\n",
       "1   1   A method for calculating a path delay in stat...\n",
       "2   2   A preventive or therapeutic agent for diabete..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_queries = pd.read_csv(\"test_queries.tsv\",sep=\"\\t\") \n",
    "\n",
    "test_queries.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test_queries = test_queries.iloc[:100,:] \n",
    "\n",
    "small_test_queries.to_csv(\"small_test_queries.tsv\", index=False, sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>passages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A method for battery charger and diagnosis wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A non transitory computer readable medium car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A method for measuring glutamyl transpeptidas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           passages\n",
       "0   0   A method for battery charger and diagnosis wi...\n",
       "1   1   A non transitory computer readable medium car...\n",
       "2   2   A method for measuring glutamyl transpeptidas..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_collections = pd.read_csv(\"test_collections.tsv\", sep=\"\\t\")  \n",
    "\n",
    "test_collections.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 2), (77886, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_test_queries.shape, test_collections.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 False 64\n",
      "\n",
      "\n",
      "[Dec 08, 08:51:14] #> Creating directory /workspace/patent_similarity/ColBERT/experiments/dirty/retrieve.py/2021-12-08_08.51.06 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Dec 08, 08:51:14] #> Creating directory /workspace/patent_similarity/ColBERT/experiments/dirty/retrieve.py/2021-12-08_08.51.06/logs/ \n",
      "\n",
      "\n",
      "[Dec 08, 08:51:14] {'root': 'experiments', 'experiment': 'dirty', 'run': '2021-12-08_08.51.06', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 512, 'doc_maxlen': 512, 'mask_punctuation': False, 'checkpoint': './experiments/dirty/train.py/2021-12-06_08.01.48/checkpoints/colbert-32000.dnn', 'bsize': 256, 'amp': True, 'queries': 'small_test_queries.tsv', 'collection': 'test_collections.tsv', 'qrels': None, 'index_root': './experiments/indexes', 'index_name': 'large_train_index', 'partitions': 65536, 'nprobe': 10, 'retrieve_only': True, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': True, 'depth': 1000} \n",
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[Dec 08, 08:51:27] #> Loading model checkpoint.\n",
      "[Dec 08, 08:51:27] #> Loading checkpoint ./experiments/dirty/train.py/2021-12-06_08.01.48/checkpoints/colbert-32000.dnn ..\n",
      "[Dec 08, 08:51:28] #> checkpoint['epoch'] = 0\n",
      "[Dec 08, 08:51:28] #> checkpoint['batch'] = 32000\n",
      "{\n",
      "    \"root\": \"experiments\",\n",
      "    \"experiment\": \"dirty\",\n",
      "    \"run\": \"2021-12-06_08.01.48\",\n",
      "    \"rank\": -1,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"dim\": 128,\n",
      "    \"query_maxlen\": 512,\n",
      "    \"doc_maxlen\": 512,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"resume\": false,\n",
      "    \"resume_optimizer\": false,\n",
      "    \"checkpoint\": null,\n",
      "    \"lr\": 3e-6,\n",
      "    \"maxsteps\": 400000,\n",
      "    \"bsize\": 8,\n",
      "    \"accumsteps\": 4,\n",
      "    \"amp\": true,\n",
      "    \"triples\": \"train_df.tsv\",\n",
      "    \"queries\": null,\n",
      "    \"collection\": null\n",
      "}\n",
      "\n",
      "\n",
      "[Dec 08, 08:51:28] #> Loading the queries from small_test_queries.tsv ...\n",
      "[Dec 08, 08:51:28] #> Got 100 queries. All QIDs are unique.\n",
      "\n",
      "[Dec 08, 08:51:28] #> Loading the FAISS index from ./experiments/indexes/large_train_index/ivfpq.65536.faiss ..\n",
      "[Dec 08, 08:51:46] #> Building the emb2pid mapping..\n",
      "[Dec 08, 08:51:46] len(self.emb2pid) = 38915192\n",
      "[Dec 08, 08:51:52] #> Logging ranked lists to /workspace/patent_similarity/ColBERT/experiments/dirty/retrieve.py/2021-12-08_08.51.06/unordered.tsv\n",
      "[Dec 08, 08:51:52] #> Embedding 100 queries in parallel...\n",
      "[Dec 08, 08:51:54] #> QueryFromText Batch Size is set to 4...\n",
      "[Dec 08, 08:51:54] #> Starting batch retrieval...\n",
      "[Dec 08, 08:51:54] #> Search in batches with faiss. \t\t Q.size() = torch.Size([100, 512, 128]), Q_faiss.size() = torch.Size([51200, 128])\n",
      "[Dec 08, 08:51:54] #> Searching from 0 to 51200...\n",
      "[Dec 08, 08:52:27] #> Lookup the PIDs..\n",
      "[Dec 08, 08:52:27] #> Converting to a list [shape = torch.Size([100, 524288])]..\n",
      "[Dec 08, 08:52:29] #> Removing duplicates (in parallel if large enough)..\n",
      "[Dec 08, 08:52:32] #> Done with embedding_ids_to_pids().\n",
      "[Dec 08, 08:52:32] #> Logging query #0 (qid 0) now...\n",
      "\n",
      "\n",
      "\n",
      "/workspace/patent_similarity/ColBERT/experiments/dirty/retrieve.py/2021-12-08_08.51.06/unordered.tsv\n",
      "#> Done.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m colbert.retrieve --amp --doc_maxlen 512 --query_maxlen 512 --bsize 256 \\\n",
    "--queries small_test_queries.tsv --partitions 65536\\\n",
    "--index_root ./experiments/indexes --index_name large_train_index \\\n",
    "--collection test_collections.tsv \\\n",
    "--checkpoint ./experiments/dirty/train.py/2021-12-06_08.01.48/checkpoints/colbert-32000.dnn --batch --retrieve_only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 False 64\n",
      "\n",
      "\n",
      "[Dec 08, 09:22:33] #> Creating directory /workspace/patent_similarity/ColBERT/experiments/dirty/rerank.py/2021-12-08_09.22.24 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Dec 08, 09:22:33] #> Creating directory /workspace/patent_similarity/ColBERT/experiments/dirty/rerank.py/2021-12-08_09.22.24/logs/ \n",
      "\n",
      "\n",
      "[Dec 08, 09:22:33] {'root': 'experiments', 'experiment': 'dirty', 'run': '2021-12-08_09.22.24', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 512, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': './experiments/dirty/train.py/2021-12-06_08.01.48/checkpoints/colbert-32000.dnn', 'bsize': 8, 'amp': True, 'queries': 'small_test_queries.tsv', 'collection': None, 'qrels': None, 'topK': './experiments/dirty/retrieve.py/2021-12-08_08.51.06/unordered.tsv', 'shortcircuit': False, 'index_root': './experiments/indexes', 'index_name': 'large_train_index', 'partitions': None, 'step': 1, 'part_range': None, 'log_scores': True, 'batch': True, 'depth': 1000} \n",
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[Dec 08, 09:22:58] #> Loading model checkpoint.\n",
      "[Dec 08, 09:22:58] #> Loading checkpoint ./experiments/dirty/train.py/2021-12-06_08.01.48/checkpoints/colbert-32000.dnn ..\n",
      "[Dec 08, 09:22:59] #> checkpoint['epoch'] = 0\n",
      "[Dec 08, 09:22:59] #> checkpoint['batch'] = 32000\n",
      "{\n",
      "    \"root\": \"experiments\",\n",
      "    \"experiment\": \"dirty\",\n",
      "    \"run\": \"2021-12-06_08.01.48\",\n",
      "    \"rank\": -1,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"dim\": 128,\n",
      "    \"query_maxlen\": 512,\n",
      "    \"doc_maxlen\": 512,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"resume\": false,\n",
      "    \"resume_optimizer\": false,\n",
      "    \"checkpoint\": null,\n",
      "    \"lr\": 3e-6,\n",
      "    \"maxsteps\": 400000,\n",
      "    \"bsize\": 8,\n",
      "    \"accumsteps\": 4,\n",
      "    \"amp\": true,\n",
      "    \"triples\": \"train_df.tsv\",\n",
      "    \"queries\": null,\n",
      "    \"collection\": null\n",
      "}\n",
      "\n",
      "\n",
      "[Dec 08, 09:22:59] #> Loading the queries from small_test_queries.tsv ...\n",
      "[Dec 08, 09:22:59] #> Got 100 queries. All QIDs are unique.\n",
      "\n",
      "[Dec 08, 09:22:59] #> Loading the top-k PIDs per query from ./experiments/dirty/retrieve.py/2021-12-08_08.51.06/unordered.tsv ...\n",
      "\n",
      "[Dec 08, 09:23:04] #> max(Ks) = 49233 , avg(Ks) = 35664.96\n",
      "[Dec 08, 09:23:04] #> Loaded the top-k per query for 100 unique queries.\n",
      "\n",
      "[Dec 08, 09:23:04] #> Launching a separate thread to load index parts asynchronously.\n",
      "[Dec 08, 09:23:04] tensor.size() =  torch.Size([24546560, 128])\n",
      "[Dec 08, 09:23:04] |> Loading ./experiments/indexes/large_train_index/0.pt ...\n",
      "[Dec 08, 09:23:08] #> Encoding all 100 queries in batches...\n",
      "[Dec 08, 09:23:09] #> Using strides [512]..\n",
      "[Dec 08, 09:23:10] tensor.size() =  torch.Size([14369656, 128])\n",
      "[Dec 08, 09:23:10] |> Loading ./experiments/indexes/large_train_index/1.pt ...\n",
      "[Dec 08, 09:23:10] #> Will process 3566496 query--document pairs in total.\n",
      "[Dec 08, 09:23:10] #> Sorting by PID..\n",
      "[Dec 08, 09:23:11] #> Fetching parts 0--1 from queue..\n",
      "[Dec 08, 09:23:11] #> Filtering PIDs to the range range(0, 49152)..\n",
      "[Dec 08, 09:23:11] #> Got 2254231 query--passage pairs in this range.\n",
      "[Dec 08, 09:23:11] #> Ranking in batches the pairs #0 through #2254231...\n",
      "[Dec 08, 09:23:11] ###--> Got 2254231 query--passage pairs in this sub-range (0, 49152).\n",
      "[Dec 08, 09:23:11] ###--> Ranking in batches the pairs #0 through #2254231 in this sub-range.\n",
      "[Dec 08, 09:23:12] #> Ranking in batches of 512 query--passage pairs...\n",
      "[Dec 08, 09:23:12] #> Processing batch #0..\n",
      "[Dec 08, 09:23:13] #> Using strides [512]..\n",
      "[Dec 08, 09:23:18] #> Processing batch #100..\n",
      "[Dec 08, 09:23:23] #> Processing batch #200..\n",
      "[Dec 08, 09:23:29] #> Processing batch #300..\n",
      "[Dec 08, 09:23:34] #> Processing batch #400..\n",
      "[Dec 08, 09:23:39] #> Processing batch #500..\n",
      "[Dec 08, 09:23:44] #> Processing batch #600..\n",
      "[Dec 08, 09:23:49] #> Processing batch #700..\n",
      "[Dec 08, 09:23:54] #> Processing batch #800..\n",
      "[Dec 08, 09:23:59] #> Processing batch #900..\n",
      "[Dec 08, 09:24:04] #> Processing batch #1000..\n",
      "[Dec 08, 09:24:10] #> Processing batch #1100..\n",
      "[Dec 08, 09:24:15] #> Processing batch #1200..\n",
      "[Dec 08, 09:24:20] #> Processing batch #1300..\n",
      "[Dec 08, 09:24:25] #> Processing batch #1400..\n",
      "[Dec 08, 09:24:30] #> Processing batch #1500..\n",
      "[Dec 08, 09:24:35] #> Processing batch #1600..\n",
      "[Dec 08, 09:24:40] #> Processing batch #1700..\n",
      "[Dec 08, 09:24:45] #> Processing batch #1800..\n",
      "[Dec 08, 09:24:50] #> Processing batch #1900..\n",
      "[Dec 08, 09:24:55] #> Processing batch #2000..\n",
      "[Dec 08, 09:25:00] #> Processing batch #2100..\n",
      "[Dec 08, 09:25:05] #> Processing batch #2200..\n",
      "[Dec 08, 09:25:10] #> Processing batch #2300..\n",
      "[Dec 08, 09:25:15] #> Processing batch #2400..\n",
      "[Dec 08, 09:25:20] #> Processing batch #2500..\n",
      "[Dec 08, 09:25:25] #> Processing batch #2600..\n",
      "[Dec 08, 09:25:30] #> Processing batch #2700..\n",
      "[Dec 08, 09:25:35] #> Processing batch #2800..\n",
      "[Dec 08, 09:25:40] #> Processing batch #2900..\n",
      "[Dec 08, 09:25:45] #> Processing batch #3000..\n",
      "[Dec 08, 09:25:50] #> Processing batch #3100..\n",
      "[Dec 08, 09:25:55] #> Processing batch #3200..\n",
      "[Dec 08, 09:26:01] #> Processing batch #3300..\n",
      "[Dec 08, 09:26:06] #> Processing batch #3400..\n",
      "[Dec 08, 09:26:11] #> Processing batch #3500..\n",
      "[Dec 08, 09:26:16] #> Processing batch #3600..\n",
      "[Dec 08, 09:26:21] #> Processing batch #3700..\n",
      "[Dec 08, 09:26:26] #> Processing batch #3800..\n",
      "[Dec 08, 09:26:31] #> Processing batch #3900..\n",
      "[Dec 08, 09:26:36] #> Processing batch #4000..\n",
      "[Dec 08, 09:26:41] #> Processing batch #4100..\n",
      "[Dec 08, 09:26:46] #> Processing batch #4200..\n",
      "[Dec 08, 09:26:51] #> Processing batch #4300..\n",
      "[Dec 08, 09:26:56] #> Processing batch #4400..\n",
      "[Dec 08, 09:26:57] #> Fetching parts 1--2 from queue..\n",
      "[Dec 08, 09:26:58] #> Filtering PIDs to the range range(49152, 77887)..\n",
      "[Dec 08, 09:26:58] #> Got 1312265 query--passage pairs in this range.\n",
      "[Dec 08, 09:26:58] #> Ranking in batches the pairs #2254231 through #3566496...\n",
      "[Dec 08, 09:26:58] ###--> Got 1312265 query--passage pairs in this sub-range (0, 28735).\n",
      "[Dec 08, 09:26:58] ###--> Ranking in batches the pairs #0 through #1312265 in this sub-range.\n",
      "[Dec 08, 09:27:00] #> Ranking in batches of 512 query--passage pairs...\n",
      "[Dec 08, 09:27:00] #> Processing batch #0..\n",
      "[Dec 08, 09:27:06] #> Processing batch #100..\n",
      "[Dec 08, 09:27:11] #> Processing batch #200..\n",
      "[Dec 08, 09:27:15] #> Processing batch #300..\n",
      "[Dec 08, 09:27:20] #> Processing batch #400..\n",
      "[Dec 08, 09:27:26] #> Processing batch #500..\n",
      "[Dec 08, 09:27:31] #> Processing batch #600..\n",
      "[Dec 08, 09:27:36] #> Processing batch #700..\n",
      "[Dec 08, 09:27:41] #> Processing batch #800..\n",
      "[Dec 08, 09:27:46] #> Processing batch #900..\n",
      "[Dec 08, 09:27:51] #> Processing batch #1000..\n",
      "[Dec 08, 09:27:56] #> Processing batch #1100..\n",
      "[Dec 08, 09:28:01] #> Processing batch #1200..\n",
      "[Dec 08, 09:28:06] #> Processing batch #1300..\n",
      "[Dec 08, 09:28:11] #> Processing batch #1400..\n",
      "[Dec 08, 09:28:16] #> Processing batch #1500..\n",
      "[Dec 08, 09:28:21] #> Processing batch #1600..\n",
      "[Dec 08, 09:28:26] #> Processing batch #1700..\n",
      "[Dec 08, 09:28:31] #> Processing batch #1800..\n",
      "[Dec 08, 09:28:36] #> Processing batch #1900..\n",
      "[Dec 08, 09:28:41] #> Processing batch #2000..\n",
      "[Dec 08, 09:28:46] #> Processing batch #2100..\n",
      "[Dec 08, 09:28:51] #> Processing batch #2200..\n",
      "[Dec 08, 09:28:56] #> Processing batch #2300..\n",
      "[Dec 08, 09:29:01] #> Processing batch #2400..\n",
      "[Dec 08, 09:29:06] #> Processing batch #2500..\n",
      "[Dec 08, 09:29:10] #> Logging ranked lists to /workspace/patent_similarity/ColBERT/experiments/dirty/rerank.py/2021-12-08_09.22.24/ranking.tsv\n",
      "[Dec 08, 09:29:10] #> Logging query #0 (qid 0) now...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> ( QID 0 ) 1)  71944 : 484.0531311035156      None\n",
      "#> ( QID 0 ) 2)  48715 : 484.0531311035156      None\n",
      "\n",
      "\n",
      "\n",
      "/workspace/patent_similarity/ColBERT/experiments/dirty/rerank.py/2021-12-08_09.22.24/ranking.tsv\n",
      "[Dec 08, 09:29:12] #> Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m colbert.rerank --batch --log-scores --topk ./experiments/dirty/retrieve.py/2021-12-08_08.51.06/unordered.tsv \\\n",
    "--query_maxlen 512 --doc_maxlen 512 --mask-punctuation \\\n",
    "--checkpoint ./experiments/dirty/train.py/2021-12-06_08.01.48/checkpoints/colbert-32000.dnn \\\n",
    "--amp --queries small_test_queries.tsv \\\n",
    "--index_root ./experiments/indexes --index_name large_train_index --bsize 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: MRR (Mean Reciprocal Rank) for 100 queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>71944</th>\n",
       "      <th>1</th>\n",
       "      <th>484.0531311035156</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48715</td>\n",
       "      <td>2</td>\n",
       "      <td>484.053131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>69480</td>\n",
       "      <td>3</td>\n",
       "      <td>484.053131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10795</td>\n",
       "      <td>4</td>\n",
       "      <td>483.817047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2853</td>\n",
       "      <td>5</td>\n",
       "      <td>483.521179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>53253</td>\n",
       "      <td>6</td>\n",
       "      <td>483.255737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  71944  1  484.0531311035156\n",
       "0  0  48715  2         484.053131\n",
       "1  0  69480  3         484.053131\n",
       "2  0  10795  4         483.817047\n",
       "3  0   2853  5         483.521179\n",
       "4  0  53253  6         483.255737"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings = pd.read_csv(\"experiments/dirty/rerank.py/2021-12-08_09.22.24/ranking.tsv\", sep=\"\\t\") \n",
    "\n",
    "rankings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>71944</td>\n",
       "      <td>1</td>\n",
       "      <td>484.0531311035156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>48715</td>\n",
       "      <td>2</td>\n",
       "      <td>484.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>69480</td>\n",
       "      <td>3</td>\n",
       "      <td>484.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10795</td>\n",
       "      <td>4</td>\n",
       "      <td>483.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2853</td>\n",
       "      <td>5</td>\n",
       "      <td>483.521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1  2                  3\n",
       "0  0  71944  1  484.0531311035156\n",
       "1  0  48715  2            484.053\n",
       "2  0  69480  3            484.053\n",
       "3  0  10795  4            483.817\n",
       "4  0   2853  5            483.521"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings = rankings.columns.to_frame().T.append(rankings, ignore_index=True) \n",
    "\n",
    "rankings.columns = range(len(rankings.columns)) \n",
    "\n",
    "rankings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load dictionary that contains (query text, similar document list) \n",
    "\n",
    "with open('query_positive_dict.pkl', 'rb') as f: \n",
    "    loaded_dict = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_texts = small_test_queries['queries'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ranks(df, idx):\n",
    "    relevant = loaded_dict[query_texts[idx]]\n",
    "    rank_i = df[df[0]==idx] \n",
    "    for i, val in enumerate(rank_i[1].values): \n",
    "        if val-1 in relevant: # due to off by one error \n",
    "            return i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR for 100 queries = 0.208\n"
     ]
    }
   ],
   "source": [
    "### MRR calculation \n",
    "ranks = [] \n",
    "for i in range(small_test_queries.shape[0]):  \n",
    "    ranks.append(calc_ranks(rankings, i))  \n",
    "\n",
    "s = 0 \n",
    "for r in ranks: \n",
    "    if r is None: \n",
    "        s += 0 \n",
    "    else: \n",
    "        s += 1/(r+1)  \n",
    "\n",
    "s = s / len(ranks)\n",
    "\n",
    "print(\"MRR for {} queries = {:.3f}\".format(len(ranks), s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: MAP (Mean Average Precision) for 100 queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(df, idx):  \n",
    "    rank_df = df[df[0] == idx]\n",
    "    relevant = loaded_dict[query_texts[idx]] \n",
    "    correct_predictions, running_sum = 0, 0 \n",
    "    rank_i = rank_df[1].values \n",
    "    for i, val in enumerate(rank_i): \n",
    "        if val-1 in relevant: # due to off by one error \n",
    "            correct_predictions += 1\n",
    "            running_sum += correct_predictions / (i+1) \n",
    "    return running_sum / len(relevant) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP for 100 queries = 0.196\n"
     ]
    }
   ],
   "source": [
    "### MAP calculation \n",
    "\n",
    "average_precisions = [] \n",
    "for i in range(small_test_queries.shape[0]): \n",
    "    average_precisions.append(average_precision(rankings, i)) \n",
    "    \n",
    "    \n",
    "print(\"MAP for {} queries = {:.3f}\".format(len(average_precisions), np.mean(average_precisions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
